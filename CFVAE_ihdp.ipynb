{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CFVAE_ihdp.ipynb",
      "provenance": [],
      "mount_file_id": "18kVB7qjBk9UQilwvY3JMogLdVzgn2GdV",
      "authorship_tag": "ABX9TyMmwrUocNIF4NswuTSAfhOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msaadsadiq/CFVAE/blob/master/CFVAE_ihdp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK7ZWaKHouHn",
        "colab_type": "text"
      },
      "source": [
        "# CFVAE - IHDP\n",
        "\n",
        "###To do \n",
        "1. run on all ihdp and average\n",
        "2. run ACIC dataset\n",
        "3. start writing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3w_tbG6hYGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pQcuYSZheHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Hyper Parameters\n",
        "EPS = 1e-15\n",
        "z_red_dims = 16\n",
        "gen_lr = 0.0001\n",
        "reg_lr = 0.00001\n",
        "b_size = 32\n",
        "total_step = 100000\n",
        "\n",
        "# writer = SummaryWriter()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLb-f3xWhf0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LEIE Data Load and normalize\n",
        "csv_loader = []\n",
        "df = pd.read_csv(\"/content/drive/My Drive/ihdp/csv/ihdp_npci_6.csv\", header=None)\n",
        "x= df.iloc[:, 5:].values\n",
        "min_max = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max.fit_transform(x)\n",
        "dfx = pd.DataFrame(x_scaled)\n",
        "dfx['trt'] = df.loc[:,0]\n",
        "dfx['y'] = df.loc[:,1]\n",
        "iter_per_epoch = int(dfx.shape[0]/b_size)\n",
        "for i in range(iter_per_epoch):\n",
        "    csv_loader.append(dfx.iloc[(i*b_size) : ((i+1)*b_size) , : ])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG098NuGhhTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Iterator \n",
        "data_iter = iter(csv_loader) #data_loader)    \n",
        "\n",
        "\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg0hfgjyhyPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoder\n",
        "class Q_net(nn.Module):  \n",
        "    def __init__(self,X_dim,N,z_dim):\n",
        "        super(Q_net, self).__init__()\n",
        "        self.lin1 = nn.Linear(X_dim, N)\n",
        "        self.lin2 = nn.Linear(N, N)\n",
        "        self.lin3gauss = nn.Linear(N, z_dim)\n",
        "    def forward(self, x):\n",
        "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        xgauss = self.lin3gauss(x)\n",
        "        return xgauss\n",
        "\n",
        "# Decoder\n",
        "class P_net(nn.Module):  \n",
        "    def __init__(self,X_dim,N,z_dim):\n",
        "        super(P_net, self).__init__()\n",
        "        self.lin1 = nn.Linear(z_dim, N)\n",
        "        self.lin2 = nn.Linear(N, N)\n",
        "        self.lin3 = nn.Linear(N, X_dim)\n",
        "    def forward(self, x):\n",
        "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.sigmoid(x)\n",
        "\n",
        "      \n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=500):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size, 1)  \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        out = F.relu(out)\n",
        "        return self.fc4(out)\n",
        "\n",
        "class Trt(nn.Module):\n",
        "    def __init__(self, input_size=20, hidden_size=500, num_classes=1):\n",
        "        super(Trt, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, num_classes) \n",
        "        # self.relu = nn.ReLU()\n",
        "        # self.fc2 = nn.Linear(hidden_size, num_classes)    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = F.relu(out)\n",
        "        return F.sigmoid(out)\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, weight=None, \n",
        "                 gamma=2., reduction='none'):\n",
        "        nn.Module.__init__(self)\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        \n",
        "    def forward(self, input_tensor, target_tensor):\n",
        "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
        "        prob = torch.exp(log_prob)\n",
        "        return F.nll_loss(\n",
        "            ((1 - prob) ** self.gamma) * log_prob, \n",
        "            target_tensor, \n",
        "            weight=self.weight,\n",
        "            reduction = self.reduction\n",
        "        )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qvrKS-8h29R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = Q_net(25,1000,z_red_dims).cuda()  #784\n",
        "P = P_net(25,1000,z_red_dims).cuda()  #784\n",
        "net_1 = Net(input_size = z_red_dims, hidden_size=500).cuda()\n",
        "net_0 = Net(input_size = z_red_dims, hidden_size=500).cuda()\n",
        "T = Trt(input_size = z_red_dims, hidden_size=100, num_classes=1).cuda()\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "FL = FocalLoss().cuda()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZValklp-h7fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encode/decode optimizers\n",
        "optim_P = torch.optim.Adam(P.parameters(), lr=gen_lr)\n",
        "optim_Q_enc = torch.optim.Adam(Q.parameters(), lr=gen_lr)\n",
        "#regularizing optimizers\n",
        "optim_Q_gen = torch.optim.Adam(Q.parameters(), lr=reg_lr)\n",
        "optim_net1 = torch.optim.Adam(net_1.parameters(), lr=reg_lr)  \n",
        "optim_net0 = torch.optim.Adam(net_0.parameters(), lr=reg_lr)  \n",
        "optim_T = torch.optim.Adam(T.parameters(), lr=reg_lr)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_0Vkuych8-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfda8f5b-859f-4c40-aa6f-c02a2d073d99"
      },
      "source": [
        "# Start training\n",
        "for step in range(total_step):\n",
        "\n",
        "    # Reset the data_iter\n",
        "    if (step+1) % iter_per_epoch == 0:\n",
        "        data_iter = iter(csv_loader)\n",
        "\n",
        "    # Fetch the images and labels and convert them to variables\n",
        "    X, y = np.split(next(data_iter),[-1],axis=1) \n",
        "    X, trt = np.split(X, [-1], axis=1)\n",
        "    X = torch.from_numpy(X.values).float()\n",
        "    y = torch.from_numpy(y.values).float()\n",
        "    trt = torch.from_numpy(trt.values).float()\n",
        "    X, y, trt = to_var(X.view(X.size(0), -1)), to_var(y), to_var(trt)\n",
        "\n",
        "    #reconstruction loss\n",
        "    P.zero_grad()\n",
        "    Q.zero_grad()\n",
        "    T.zero_grad()\n",
        "    net_1.zero_grad()\n",
        "    net_0.zero_grad()\n",
        "    \n",
        "    z_sample = Q(X)   #encode to z\n",
        "    X_sample = P(z_sample) #decode to X reconstruction\n",
        "    recon_loss = F.binary_cross_entropy(X_sample+EPS,X+EPS) #loss_fn(X_sample,images)\n",
        "    recon_loss.backward()\n",
        "\n",
        "    optim_P.step()\n",
        "    optim_Q_enc.step()\n",
        "    \n",
        "    # Discriminator\n",
        "    Q.train()\n",
        "    z_fake_gauss = Q(X)\n",
        "    T_fake = T(z_fake_gauss)\n",
        "    G_loss = F.binary_cross_entropy(T_fake+EPS,trt+EPS) #FL(argmax,trt).float().mean() \n",
        "    G_loss.backward()\n",
        "    optim_Q_gen.step()\n",
        "    \n",
        "\n",
        "    # Q.eval()\n",
        "    # z_fake_gauss = Q(X)\n",
        "    # T_fake = T(z_fake_gauss)\n",
        "    # T_loss = F.binary_cross_entropy(T_fake+EPS,trt+EPS) #FL(argmax,trt).float().mean() \n",
        "    # T_loss.backward()\n",
        "    # optim_T.step()  \n",
        "\n",
        "    # # for net 2\n",
        "    # Q.eval()\n",
        "    # net_2_real_gauss = net_2(z_real_gauss)\n",
        "    # z_fake_gauss = Q(images)\n",
        "    # net_2_fake_gauss = net_2(z_fake_gauss)\n",
        "    # net_2_loss = loss_fn(net_2_real_gauss, net_2_fake_gauss) \n",
        "    # net_2_loss.backward()\n",
        "    # optim_net2.step()\n",
        "    # P.zero_grad()\n",
        "    # Q.zero_grad()\n",
        "    # net_1.zero_grad()\n",
        "    # net_2.zero_grad()\n",
        "\n",
        "    # Generator\n",
        "    Q.eval()\n",
        "    z_fake_gauss = Q(X)\n",
        "    net_1_fake_gauss = net_1(z_fake_gauss)\n",
        "    net_1_out_fake_gauss = trt * net_1_fake_gauss\n",
        "    net1loss =  loss_fn(trt*y, net_1_out_fake_gauss)\n",
        "    net1loss.backward()\n",
        "    optim_net1.step()\n",
        "\n",
        "\n",
        "    # for net 0, trt=0\n",
        "    Q.eval()\n",
        "    z_fake_gauss = Q(X)\n",
        "    net_0_fake_gauss = net_0(z_fake_gauss)\n",
        "    net_0_out_fake_gauss = (1-trt) * net_0_fake_gauss\n",
        "    net0loss =  loss_fn( ((1-trt)*y), net_0_out_fake_gauss)\n",
        "    net0loss.backward()\n",
        "    optim_net0.step()\n",
        "\n",
        " \n",
        "\n",
        "    # writer.add_scalar('Generator Loss', G_loss.data, step)\n",
        "    # writer.add_scalar('Classification Loss', net_loss.data, step)\n",
        "    # writer.add_scalar('Reconstruction Loss', recon_loss.data, step)\n",
        "    \n",
        "    if (step+1) % 100 == 0:\n",
        "        print ('Step [%d/%d], recon_Loss: %.4f, G_Loss: %.4f, net1_Loss: %.4f, net2_Loss: %.4f, '\n",
        "        %(step+1, total_step, recon_loss.data, G_loss.data, net1loss.data, net0loss.data))\n",
        "                   "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [100/100000], recon_Loss: 0.4635, G_Loss: 0.6932, net1_Loss: 353.9930, net2_Loss: 114.8944, \n",
            "Step [200/100000], recon_Loss: 0.3529, G_Loss: 0.7154, net1_Loss: 81.2380, net2_Loss: 126.4741, \n",
            "Step [300/100000], recon_Loss: 0.3152, G_Loss: 0.6931, net1_Loss: 60.2674, net2_Loss: 46.5037, \n",
            "Step [400/100000], recon_Loss: 0.2240, G_Loss: 0.6909, net1_Loss: 11.5039, net2_Loss: 31.5900, \n",
            "Step [500/100000], recon_Loss: 0.1816, G_Loss: 0.6932, net1_Loss: 6.6861, net2_Loss: 57.1821, \n",
            "Step [600/100000], recon_Loss: 0.2330, G_Loss: 0.6931, net1_Loss: 9.6341, net2_Loss: 48.9395, \n",
            "Step [700/100000], recon_Loss: 0.2246, G_Loss: 0.7151, net1_Loss: 7.8090, net2_Loss: 53.1652, \n",
            "Step [800/100000], recon_Loss: 0.1674, G_Loss: 0.6928, net1_Loss: 17.9285, net2_Loss: 31.8213, \n",
            "Step [900/100000], recon_Loss: 0.1732, G_Loss: 0.7186, net1_Loss: 1.1977, net2_Loss: 51.9065, \n",
            "Step [1000/100000], recon_Loss: 0.1605, G_Loss: 0.7015, net1_Loss: 0.1459, net2_Loss: 22.9237, \n",
            "Step [1100/100000], recon_Loss: 0.1473, G_Loss: 0.7038, net1_Loss: 11.7555, net2_Loss: 15.6227, \n",
            "Step [1200/100000], recon_Loss: 0.1503, G_Loss: 0.7033, net1_Loss: 0.0000, net2_Loss: 31.3468, \n",
            "Step [1300/100000], recon_Loss: 0.1439, G_Loss: 0.7008, net1_Loss: 0.0054, net2_Loss: 25.5150, \n",
            "Step [1400/100000], recon_Loss: 0.1480, G_Loss: 0.7017, net1_Loss: 5.1553, net2_Loss: 21.0494, \n",
            "Step [1500/100000], recon_Loss: 0.1402, G_Loss: 0.6899, net1_Loss: 2.8127, net2_Loss: 17.4375, \n",
            "Step [1600/100000], recon_Loss: 0.1411, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 40.5995, \n",
            "Step [1700/100000], recon_Loss: 0.1331, G_Loss: 0.6932, net1_Loss: 18.2515, net2_Loss: 20.2769, \n",
            "Step [1800/100000], recon_Loss: 0.1394, G_Loss: 0.6931, net1_Loss: 1.3777, net2_Loss: 21.5010, \n",
            "Step [1900/100000], recon_Loss: 0.1408, G_Loss: 0.6931, net1_Loss: 5.3673, net2_Loss: 11.0852, \n",
            "Step [2000/100000], recon_Loss: 0.1411, G_Loss: 0.6931, net1_Loss: 8.1648, net2_Loss: 19.9584, \n",
            "Step [2100/100000], recon_Loss: 0.1423, G_Loss: 0.7089, net1_Loss: 1.3694, net2_Loss: 39.8718, \n",
            "Step [2200/100000], recon_Loss: 0.1377, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 22.6837, \n",
            "Step [2300/100000], recon_Loss: 0.1460, G_Loss: 0.6931, net1_Loss: 3.9198, net2_Loss: 30.5862, \n",
            "Step [2400/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 1.7257, net2_Loss: 15.8614, \n",
            "Step [2500/100000], recon_Loss: 0.1410, G_Loss: 0.6801, net1_Loss: 3.8194, net2_Loss: 37.4296, \n",
            "Step [2600/100000], recon_Loss: 0.1346, G_Loss: 0.6931, net1_Loss: 3.5790, net2_Loss: 20.1507, \n",
            "Step [2700/100000], recon_Loss: 0.1360, G_Loss: 0.6845, net1_Loss: 1.6274, net2_Loss: 15.6594, \n",
            "Step [2800/100000], recon_Loss: 0.1345, G_Loss: 0.6797, net1_Loss: 4.0753, net2_Loss: 24.6948, \n",
            "Step [2900/100000], recon_Loss: 0.1370, G_Loss: 0.6931, net1_Loss: 2.7965, net2_Loss: 22.1749, \n",
            "Step [3000/100000], recon_Loss: 0.1405, G_Loss: 0.6950, net1_Loss: 0.3301, net2_Loss: 26.3681, \n",
            "Step [3100/100000], recon_Loss: 0.1280, G_Loss: 0.6810, net1_Loss: 1.5470, net2_Loss: 10.8467, \n",
            "Step [3200/100000], recon_Loss: 0.1386, G_Loss: 0.6887, net1_Loss: 0.4035, net2_Loss: 23.6092, \n",
            "Step [3300/100000], recon_Loss: 0.1306, G_Loss: 0.6931, net1_Loss: 0.0674, net2_Loss: 12.3765, \n",
            "Step [3400/100000], recon_Loss: 0.1306, G_Loss: 0.7044, net1_Loss: 5.0873, net2_Loss: 8.0697, \n",
            "Step [3500/100000], recon_Loss: 0.1360, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 23.0422, \n",
            "Step [3600/100000], recon_Loss: 0.1308, G_Loss: 0.6979, net1_Loss: 0.7322, net2_Loss: 14.4684, \n",
            "Step [3700/100000], recon_Loss: 0.1329, G_Loss: 0.6984, net1_Loss: 3.9823, net2_Loss: 7.8954, \n",
            "Step [3800/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0978, net2_Loss: 6.3769, \n",
            "Step [3900/100000], recon_Loss: 0.1316, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 18.7518, \n",
            "Step [4000/100000], recon_Loss: 0.1258, G_Loss: 0.6931, net1_Loss: 9.9970, net2_Loss: 8.9677, \n",
            "Step [4100/100000], recon_Loss: 0.1312, G_Loss: 0.6931, net1_Loss: 0.6533, net2_Loss: 14.1352, \n",
            "Step [4200/100000], recon_Loss: 0.1335, G_Loss: 0.6931, net1_Loss: 0.3317, net2_Loss: 8.2342, \n",
            "Step [4300/100000], recon_Loss: 0.1361, G_Loss: 0.6938, net1_Loss: 4.8402, net2_Loss: 8.3138, \n",
            "Step [4400/100000], recon_Loss: 0.1328, G_Loss: 0.7080, net1_Loss: 0.0374, net2_Loss: 24.6070, \n",
            "Step [4500/100000], recon_Loss: 0.1333, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 13.4101, \n",
            "Step [4600/100000], recon_Loss: 0.1376, G_Loss: 0.6931, net1_Loss: 1.2197, net2_Loss: 15.2689, \n",
            "Step [4700/100000], recon_Loss: 0.1263, G_Loss: 0.6931, net1_Loss: 0.1299, net2_Loss: 8.2670, \n",
            "Step [4800/100000], recon_Loss: 0.1361, G_Loss: 0.6827, net1_Loss: 2.1612, net2_Loss: 21.7598, \n",
            "Step [4900/100000], recon_Loss: 0.1302, G_Loss: 0.6931, net1_Loss: 1.3848, net2_Loss: 10.2425, \n",
            "Step [5000/100000], recon_Loss: 0.1314, G_Loss: 0.6775, net1_Loss: 0.7618, net2_Loss: 8.9599, \n",
            "Step [5100/100000], recon_Loss: 0.1326, G_Loss: 0.6813, net1_Loss: 0.3184, net2_Loss: 20.6694, \n",
            "Step [5200/100000], recon_Loss: 0.1342, G_Loss: 0.6931, net1_Loss: 0.7038, net2_Loss: 8.6923, \n",
            "Step [5300/100000], recon_Loss: 0.1318, G_Loss: 0.6842, net1_Loss: 0.1839, net2_Loss: 8.6932, \n",
            "Step [5400/100000], recon_Loss: 0.1226, G_Loss: 0.6771, net1_Loss: 1.0890, net2_Loss: 5.7046, \n",
            "Step [5500/100000], recon_Loss: 0.1363, G_Loss: 0.6931, net1_Loss: 0.3827, net2_Loss: 8.7913, \n",
            "Step [5600/100000], recon_Loss: 0.1310, G_Loss: 0.6944, net1_Loss: 0.4513, net2_Loss: 8.3131, \n",
            "Step [5700/100000], recon_Loss: 0.1288, G_Loss: 0.7246, net1_Loss: 2.0995, net2_Loss: 5.2335, \n",
            "Step [5800/100000], recon_Loss: 0.1320, G_Loss: 0.6975, net1_Loss: 0.0000, net2_Loss: 11.7633, \n",
            "Step [5900/100000], recon_Loss: 0.1270, G_Loss: 0.6931, net1_Loss: 0.1019, net2_Loss: 9.9383, \n",
            "Step [6000/100000], recon_Loss: 0.1319, G_Loss: 0.6858, net1_Loss: 2.3468, net2_Loss: 5.1352, \n",
            "Step [6100/100000], recon_Loss: 0.1276, G_Loss: 0.6990, net1_Loss: 0.0422, net2_Loss: 3.9867, \n",
            "Step [6200/100000], recon_Loss: 0.1276, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 11.3136, \n",
            "Step [6300/100000], recon_Loss: 0.1222, G_Loss: 0.6964, net1_Loss: 1.9071, net2_Loss: 4.7921, \n",
            "Step [6400/100000], recon_Loss: 0.1289, G_Loss: 0.6931, net1_Loss: 0.8347, net2_Loss: 6.6218, \n",
            "Step [6500/100000], recon_Loss: 0.1318, G_Loss: 0.6931, net1_Loss: 0.2271, net2_Loss: 6.3976, \n",
            "Step [6600/100000], recon_Loss: 0.1346, G_Loss: 0.6931, net1_Loss: 2.4323, net2_Loss: 5.6873, \n",
            "Step [6700/100000], recon_Loss: 0.1283, G_Loss: 0.7129, net1_Loss: 0.1248, net2_Loss: 14.6059, \n",
            "Step [6800/100000], recon_Loss: 0.1296, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 6.5194, \n",
            "Step [6900/100000], recon_Loss: 0.1346, G_Loss: 0.6931, net1_Loss: 0.0252, net2_Loss: 6.9254, \n",
            "Step [7000/100000], recon_Loss: 0.1239, G_Loss: 0.6950, net1_Loss: 0.2042, net2_Loss: 8.1823, \n",
            "Step [7100/100000], recon_Loss: 0.1341, G_Loss: 0.6727, net1_Loss: 1.2419, net2_Loss: 12.9899, \n",
            "Step [7200/100000], recon_Loss: 0.1298, G_Loss: 0.6931, net1_Loss: 0.9084, net2_Loss: 8.8409, \n",
            "Step [7300/100000], recon_Loss: 0.1288, G_Loss: 0.6976, net1_Loss: 0.0960, net2_Loss: 5.6276, \n",
            "Step [7400/100000], recon_Loss: 0.1282, G_Loss: 0.6863, net1_Loss: 0.2347, net2_Loss: 5.9213, \n",
            "Step [7500/100000], recon_Loss: 0.1324, G_Loss: 0.6931, net1_Loss: 0.2381, net2_Loss: 5.1632, \n",
            "Step [7600/100000], recon_Loss: 0.1288, G_Loss: 0.6973, net1_Loss: 0.0289, net2_Loss: 5.9488, \n",
            "Step [7700/100000], recon_Loss: 0.1210, G_Loss: 0.6670, net1_Loss: 0.9437, net2_Loss: 2.4810, \n",
            "Step [7800/100000], recon_Loss: 0.1345, G_Loss: 0.6916, net1_Loss: 0.0849, net2_Loss: 3.9394, \n",
            "Step [7900/100000], recon_Loss: 0.1276, G_Loss: 0.6954, net1_Loss: 0.0469, net2_Loss: 5.2083, \n",
            "Step [8000/100000], recon_Loss: 0.1271, G_Loss: 0.6765, net1_Loss: 0.5894, net2_Loss: 3.1592, \n",
            "Step [8100/100000], recon_Loss: 0.1311, G_Loss: 0.6946, net1_Loss: 0.0000, net2_Loss: 8.8187, \n",
            "Step [8200/100000], recon_Loss: 0.1263, G_Loss: 0.6931, net1_Loss: 0.3731, net2_Loss: 5.4226, \n",
            "Step [8300/100000], recon_Loss: 0.1305, G_Loss: 0.7103, net1_Loss: 1.0728, net2_Loss: 3.0409, \n",
            "Step [8400/100000], recon_Loss: 0.1264, G_Loss: 0.6907, net1_Loss: 0.2638, net2_Loss: 2.8498, \n",
            "Step [8500/100000], recon_Loss: 0.1266, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 4.6557, \n",
            "Step [8600/100000], recon_Loss: 0.1201, G_Loss: 0.6931, net1_Loss: 1.6464, net2_Loss: 2.4048, \n",
            "Step [8700/100000], recon_Loss: 0.1278, G_Loss: 0.6856, net1_Loss: 0.1262, net2_Loss: 3.4597, \n",
            "Step [8800/100000], recon_Loss: 0.1303, G_Loss: 0.6931, net1_Loss: 0.0766, net2_Loss: 3.7752, \n",
            "Step [8900/100000], recon_Loss: 0.1333, G_Loss: 0.6931, net1_Loss: 0.5164, net2_Loss: 2.6586, \n",
            "Step [9000/100000], recon_Loss: 0.1283, G_Loss: 0.7272, net1_Loss: 0.0400, net2_Loss: 9.4136, \n",
            "Step [9100/100000], recon_Loss: 0.1287, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 4.7506, \n",
            "Step [9200/100000], recon_Loss: 0.1345, G_Loss: 0.6931, net1_Loss: 0.1905, net2_Loss: 6.6186, \n",
            "Step [9300/100000], recon_Loss: 0.1235, G_Loss: 0.6931, net1_Loss: 0.3947, net2_Loss: 2.7098, \n",
            "Step [9400/100000], recon_Loss: 0.1331, G_Loss: 0.6719, net1_Loss: 0.3634, net2_Loss: 7.4178, \n",
            "Step [9500/100000], recon_Loss: 0.1273, G_Loss: 0.6931, net1_Loss: 0.0976, net2_Loss: 5.6227, \n",
            "Step [9600/100000], recon_Loss: 0.1280, G_Loss: 0.6802, net1_Loss: 0.2180, net2_Loss: 3.2598, \n",
            "Step [9700/100000], recon_Loss: 0.1280, G_Loss: 0.6744, net1_Loss: 0.4030, net2_Loss: 4.1529, \n",
            "Step [9800/100000], recon_Loss: 0.1308, G_Loss: 0.6931, net1_Loss: 0.1560, net2_Loss: 1.7233, \n",
            "Step [9900/100000], recon_Loss: 0.1274, G_Loss: 0.6864, net1_Loss: 0.2191, net2_Loss: 3.0878, \n",
            "Step [10000/100000], recon_Loss: 0.1207, G_Loss: 0.6740, net1_Loss: 0.3709, net2_Loss: 1.4853, \n",
            "Step [10100/100000], recon_Loss: 0.1342, G_Loss: 0.6931, net1_Loss: 0.1284, net2_Loss: 2.4985, \n",
            "Step [10200/100000], recon_Loss: 0.1273, G_Loss: 0.7288, net1_Loss: 0.0652, net2_Loss: 4.1494, \n",
            "Step [10300/100000], recon_Loss: 0.1266, G_Loss: 0.6890, net1_Loss: 0.0797, net2_Loss: 1.5060, \n",
            "Step [10400/100000], recon_Loss: 0.1317, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 3.0111, \n",
            "Step [10500/100000], recon_Loss: 0.1244, G_Loss: 0.6956, net1_Loss: 0.0265, net2_Loss: 3.2396, \n",
            "Step [10600/100000], recon_Loss: 0.1307, G_Loss: 0.6843, net1_Loss: 0.4564, net2_Loss: 4.0022, \n",
            "Step [10700/100000], recon_Loss: 0.1263, G_Loss: 0.6997, net1_Loss: 0.2474, net2_Loss: 2.3818, \n",
            "Step [10800/100000], recon_Loss: 0.1259, G_Loss: 0.6955, net1_Loss: 0.0000, net2_Loss: 5.2554, \n",
            "Step [10900/100000], recon_Loss: 0.1194, G_Loss: 0.6923, net1_Loss: 0.4130, net2_Loss: 1.1257, \n",
            "Step [11000/100000], recon_Loss: 0.1273, G_Loss: 0.6931, net1_Loss: 0.3319, net2_Loss: 2.4260, \n",
            "Step [11100/100000], recon_Loss: 0.1302, G_Loss: 0.6931, net1_Loss: 0.0512, net2_Loss: 2.4808, \n",
            "Step [11200/100000], recon_Loss: 0.1316, G_Loss: 0.6931, net1_Loss: 0.1044, net2_Loss: 1.1793, \n",
            "Step [11300/100000], recon_Loss: 0.1276, G_Loss: 0.7313, net1_Loss: 0.0192, net2_Loss: 6.3209, \n",
            "Step [11400/100000], recon_Loss: 0.1286, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 2.9943, \n",
            "Step [11500/100000], recon_Loss: 0.1338, G_Loss: 0.6931, net1_Loss: 0.2462, net2_Loss: 8.9316, \n",
            "Step [11600/100000], recon_Loss: 0.1236, G_Loss: 0.6945, net1_Loss: 0.6084, net2_Loss: 4.8255, \n",
            "Step [11700/100000], recon_Loss: 0.1320, G_Loss: 0.6751, net1_Loss: 0.1109, net2_Loss: 3.2661, \n",
            "Step [11800/100000], recon_Loss: 0.1260, G_Loss: 0.6931, net1_Loss: 0.1410, net2_Loss: 2.0701, \n",
            "Step [11900/100000], recon_Loss: 0.1277, G_Loss: 0.6883, net1_Loss: 0.1263, net2_Loss: 0.8744, \n",
            "Step [12000/100000], recon_Loss: 0.1274, G_Loss: 0.6774, net1_Loss: 0.0718, net2_Loss: 1.2334, \n",
            "Step [12100/100000], recon_Loss: 0.1306, G_Loss: 0.6931, net1_Loss: 0.0574, net2_Loss: 0.8773, \n",
            "Step [12200/100000], recon_Loss: 0.1266, G_Loss: 0.6793, net1_Loss: 0.0012, net2_Loss: 2.1887, \n",
            "Step [12300/100000], recon_Loss: 0.1198, G_Loss: 0.6583, net1_Loss: 0.0394, net2_Loss: 0.5196, \n",
            "Step [12400/100000], recon_Loss: 0.1334, G_Loss: 0.6931, net1_Loss: 0.0105, net2_Loss: 1.6545, \n",
            "Step [12500/100000], recon_Loss: 0.1261, G_Loss: 0.6931, net1_Loss: 0.0417, net2_Loss: 2.9160, \n",
            "Step [12600/100000], recon_Loss: 0.1260, G_Loss: 0.6849, net1_Loss: 0.3351, net2_Loss: 0.6358, \n",
            "Step [12700/100000], recon_Loss: 0.1307, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 3.4427, \n",
            "Step [12800/100000], recon_Loss: 0.1238, G_Loss: 0.6931, net1_Loss: 0.0820, net2_Loss: 5.9776, \n",
            "Step [12900/100000], recon_Loss: 0.1293, G_Loss: 0.7102, net1_Loss: 0.2180, net2_Loss: 1.1295, \n",
            "Step [13000/100000], recon_Loss: 0.1251, G_Loss: 0.6801, net1_Loss: 0.0981, net2_Loss: 0.9362, \n",
            "Step [13100/100000], recon_Loss: 0.1254, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.2329, \n",
            "Step [13200/100000], recon_Loss: 0.1194, G_Loss: 0.6931, net1_Loss: 0.5950, net2_Loss: 0.8239, \n",
            "Step [13300/100000], recon_Loss: 0.1269, G_Loss: 0.6812, net1_Loss: 0.1062, net2_Loss: 1.8915, \n",
            "Step [13400/100000], recon_Loss: 0.1306, G_Loss: 0.6931, net1_Loss: 0.9304, net2_Loss: 2.5469, \n",
            "Step [13500/100000], recon_Loss: 0.1314, G_Loss: 0.6931, net1_Loss: 0.0110, net2_Loss: 1.6587, \n",
            "Step [13600/100000], recon_Loss: 0.1266, G_Loss: 0.7062, net1_Loss: 0.0008, net2_Loss: 3.2044, \n",
            "Step [13700/100000], recon_Loss: 0.1282, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 2.8420, \n",
            "Step [13800/100000], recon_Loss: 0.1321, G_Loss: 0.6931, net1_Loss: 0.0517, net2_Loss: 1.1465, \n",
            "Step [13900/100000], recon_Loss: 0.1226, G_Loss: 0.6931, net1_Loss: 0.1390, net2_Loss: 1.2682, \n",
            "Step [14000/100000], recon_Loss: 0.1321, G_Loss: 0.6766, net1_Loss: 0.0495, net2_Loss: 2.4738, \n",
            "Step [14100/100000], recon_Loss: 0.1260, G_Loss: 0.6931, net1_Loss: 0.6853, net2_Loss: 0.7602, \n",
            "Step [14200/100000], recon_Loss: 0.1268, G_Loss: 0.6798, net1_Loss: 0.0840, net2_Loss: 0.5577, \n",
            "Step [14300/100000], recon_Loss: 0.1265, G_Loss: 0.6803, net1_Loss: 0.1534, net2_Loss: 1.3952, \n",
            "Step [14400/100000], recon_Loss: 0.1307, G_Loss: 0.6931, net1_Loss: 0.0534, net2_Loss: 0.4728, \n",
            "Step [14500/100000], recon_Loss: 0.1265, G_Loss: 0.6785, net1_Loss: 0.0355, net2_Loss: 2.2758, \n",
            "Step [14600/100000], recon_Loss: 0.1195, G_Loss: 0.6642, net1_Loss: 0.1625, net2_Loss: 1.0572, \n",
            "Step [14700/100000], recon_Loss: 0.1343, G_Loss: 0.6931, net1_Loss: 0.2788, net2_Loss: 11.8081, \n",
            "Step [14800/100000], recon_Loss: 0.1261, G_Loss: 0.6931, net1_Loss: 0.0592, net2_Loss: 8.5001, \n",
            "Step [14900/100000], recon_Loss: 0.1259, G_Loss: 0.6770, net1_Loss: 0.1969, net2_Loss: 0.4868, \n",
            "Step [15000/100000], recon_Loss: 0.1306, G_Loss: 0.6949, net1_Loss: 0.0000, net2_Loss: 1.5318, \n",
            "Step [15100/100000], recon_Loss: 0.1230, G_Loss: 0.6931, net1_Loss: 0.0581, net2_Loss: 1.1788, \n",
            "Step [15200/100000], recon_Loss: 0.1296, G_Loss: 0.6758, net1_Loss: 0.1636, net2_Loss: 0.9118, \n",
            "Step [15300/100000], recon_Loss: 0.1255, G_Loss: 0.6926, net1_Loss: 0.0339, net2_Loss: 0.8420, \n",
            "Step [15400/100000], recon_Loss: 0.1253, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.1958, \n",
            "Step [15500/100000], recon_Loss: 0.1184, G_Loss: 0.6779, net1_Loss: 0.5971, net2_Loss: 0.6716, \n",
            "Step [15600/100000], recon_Loss: 0.1269, G_Loss: 0.6805, net1_Loss: 0.3619, net2_Loss: 1.4826, \n",
            "Step [15700/100000], recon_Loss: 0.1297, G_Loss: 0.6931, net1_Loss: 0.1049, net2_Loss: 2.3958, \n",
            "Step [15800/100000], recon_Loss: 0.1310, G_Loss: 0.6931, net1_Loss: 0.1289, net2_Loss: 1.0397, \n",
            "Step [15900/100000], recon_Loss: 0.1260, G_Loss: 0.7052, net1_Loss: 0.0001, net2_Loss: 4.5532, \n",
            "Step [16000/100000], recon_Loss: 0.1280, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 2.1988, \n",
            "Step [16100/100000], recon_Loss: 0.1322, G_Loss: 0.6931, net1_Loss: 0.0134, net2_Loss: 1.1743, \n",
            "Step [16200/100000], recon_Loss: 0.1220, G_Loss: 0.6960, net1_Loss: 0.1359, net2_Loss: 1.1861, \n",
            "Step [16300/100000], recon_Loss: 0.1317, G_Loss: 0.6722, net1_Loss: 0.0570, net2_Loss: 1.6065, \n",
            "Step [16400/100000], recon_Loss: 0.1262, G_Loss: 0.6931, net1_Loss: 0.0912, net2_Loss: 1.0422, \n",
            "Step [16500/100000], recon_Loss: 0.1273, G_Loss: 0.6679, net1_Loss: 0.1935, net2_Loss: 0.8392, \n",
            "Step [16600/100000], recon_Loss: 0.1269, G_Loss: 0.6749, net1_Loss: 0.0747, net2_Loss: 0.7874, \n",
            "Step [16700/100000], recon_Loss: 0.1306, G_Loss: 0.6931, net1_Loss: 0.0860, net2_Loss: 0.5736, \n",
            "Step [16800/100000], recon_Loss: 0.1267, G_Loss: 0.6837, net1_Loss: 0.1097, net2_Loss: 1.5595, \n",
            "Step [16900/100000], recon_Loss: 0.1196, G_Loss: 0.6693, net1_Loss: 0.9369, net2_Loss: 0.6423, \n",
            "Step [17000/100000], recon_Loss: 0.1328, G_Loss: 0.7022, net1_Loss: 0.1241, net2_Loss: 6.7520, \n",
            "Step [17100/100000], recon_Loss: 0.1257, G_Loss: 0.6931, net1_Loss: 0.0144, net2_Loss: 2.7367, \n",
            "Step [17200/100000], recon_Loss: 0.1253, G_Loss: 0.6770, net1_Loss: 0.0616, net2_Loss: 1.0232, \n",
            "Step [17300/100000], recon_Loss: 0.1304, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.4134, \n",
            "Step [17400/100000], recon_Loss: 0.1231, G_Loss: 0.6951, net1_Loss: 0.0210, net2_Loss: 2.3128, \n",
            "Step [17500/100000], recon_Loss: 0.1290, G_Loss: 0.6877, net1_Loss: 0.1216, net2_Loss: 1.4230, \n",
            "Step [17600/100000], recon_Loss: 0.1253, G_Loss: 0.6949, net1_Loss: 0.0903, net2_Loss: 1.6066, \n",
            "Step [17700/100000], recon_Loss: 0.1255, G_Loss: 0.6962, net1_Loss: 0.0000, net2_Loss: 0.7821, \n",
            "Step [17800/100000], recon_Loss: 0.1182, G_Loss: 0.6911, net1_Loss: 0.2663, net2_Loss: 0.5078, \n",
            "Step [17900/100000], recon_Loss: 0.1265, G_Loss: 0.6816, net1_Loss: 0.2097, net2_Loss: 0.8105, \n",
            "Step [18000/100000], recon_Loss: 0.1298, G_Loss: 0.6931, net1_Loss: 0.0791, net2_Loss: 2.4704, \n",
            "Step [18100/100000], recon_Loss: 0.1316, G_Loss: 0.6940, net1_Loss: 0.1764, net2_Loss: 2.1064, \n",
            "Step [18200/100000], recon_Loss: 0.1262, G_Loss: 0.7014, net1_Loss: 0.0029, net2_Loss: 1.7577, \n",
            "Step [18300/100000], recon_Loss: 0.1278, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.6797, \n",
            "Step [18400/100000], recon_Loss: 0.1314, G_Loss: 0.6931, net1_Loss: 0.0026, net2_Loss: 4.9902, \n",
            "Step [18500/100000], recon_Loss: 0.1217, G_Loss: 0.6931, net1_Loss: 0.0569, net2_Loss: 1.9005, \n",
            "Step [18600/100000], recon_Loss: 0.1319, G_Loss: 0.6640, net1_Loss: 0.1004, net2_Loss: 4.5527, \n",
            "Step [18700/100000], recon_Loss: 0.1269, G_Loss: 0.6931, net1_Loss: 1.5609, net2_Loss: 3.4336, \n",
            "Step [18800/100000], recon_Loss: 0.1271, G_Loss: 0.6691, net1_Loss: 0.1681, net2_Loss: 1.1772, \n",
            "Step [18900/100000], recon_Loss: 0.1262, G_Loss: 0.6925, net1_Loss: 0.1871, net2_Loss: 0.7295, \n",
            "Step [19000/100000], recon_Loss: 0.1302, G_Loss: 0.6931, net1_Loss: 0.0988, net2_Loss: 0.5687, \n",
            "Step [19100/100000], recon_Loss: 0.1256, G_Loss: 0.6809, net1_Loss: 0.0348, net2_Loss: 1.0389, \n",
            "Step [19200/100000], recon_Loss: 0.1191, G_Loss: 0.6652, net1_Loss: 0.0362, net2_Loss: 0.3579, \n",
            "Step [19300/100000], recon_Loss: 0.1324, G_Loss: 0.6931, net1_Loss: 0.0009, net2_Loss: 1.1757, \n",
            "Step [19400/100000], recon_Loss: 0.1253, G_Loss: 0.6931, net1_Loss: 0.0054, net2_Loss: 1.7246, \n",
            "Step [19500/100000], recon_Loss: 0.1253, G_Loss: 0.6640, net1_Loss: 0.1477, net2_Loss: 0.4266, \n",
            "Step [19600/100000], recon_Loss: 0.1298, G_Loss: 0.6949, net1_Loss: 0.0000, net2_Loss: 0.6868, \n",
            "Step [19700/100000], recon_Loss: 0.1236, G_Loss: 0.6931, net1_Loss: 0.0857, net2_Loss: 2.1838, \n",
            "Step [19800/100000], recon_Loss: 0.1287, G_Loss: 0.6853, net1_Loss: 0.0715, net2_Loss: 0.4854, \n",
            "Step [19900/100000], recon_Loss: 0.1249, G_Loss: 0.6860, net1_Loss: 0.2943, net2_Loss: 0.4697, \n",
            "Step [20000/100000], recon_Loss: 0.1254, G_Loss: 0.6943, net1_Loss: 0.0000, net2_Loss: 3.6818, \n",
            "Step [20100/100000], recon_Loss: 0.1181, G_Loss: 0.6814, net1_Loss: 0.3073, net2_Loss: 0.6877, \n",
            "Step [20200/100000], recon_Loss: 0.1263, G_Loss: 0.6837, net1_Loss: 0.1468, net2_Loss: 0.6411, \n",
            "Step [20300/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0121, net2_Loss: 1.3272, \n",
            "Step [20400/100000], recon_Loss: 0.1309, G_Loss: 0.6931, net1_Loss: 0.0049, net2_Loss: 0.6473, \n",
            "Step [20500/100000], recon_Loss: 0.1259, G_Loss: 0.7149, net1_Loss: 0.0003, net2_Loss: 1.4774, \n",
            "Step [20600/100000], recon_Loss: 0.1277, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.8597, \n",
            "Step [20700/100000], recon_Loss: 0.1313, G_Loss: 0.6931, net1_Loss: 0.0179, net2_Loss: 0.2899, \n",
            "Step [20800/100000], recon_Loss: 0.1215, G_Loss: 0.6931, net1_Loss: 0.0621, net2_Loss: 0.2792, \n",
            "Step [20900/100000], recon_Loss: 0.1316, G_Loss: 0.6592, net1_Loss: 0.0221, net2_Loss: 1.3167, \n",
            "Step [21000/100000], recon_Loss: 0.1261, G_Loss: 0.6931, net1_Loss: 0.1923, net2_Loss: 0.3864, \n",
            "Step [21100/100000], recon_Loss: 0.1266, G_Loss: 0.6484, net1_Loss: 0.0695, net2_Loss: 1.0863, \n",
            "Step [21200/100000], recon_Loss: 0.1260, G_Loss: 0.6735, net1_Loss: 0.3449, net2_Loss: 1.7415, \n",
            "Step [21300/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0572, net2_Loss: 0.3161, \n",
            "Step [21400/100000], recon_Loss: 0.1259, G_Loss: 0.6775, net1_Loss: 0.0559, net2_Loss: 4.0598, \n",
            "Step [21500/100000], recon_Loss: 0.1190, G_Loss: 0.6584, net1_Loss: 0.1218, net2_Loss: 3.3332, \n",
            "Step [21600/100000], recon_Loss: 0.1327, G_Loss: 0.6931, net1_Loss: 0.0107, net2_Loss: 1.2046, \n",
            "Step [21700/100000], recon_Loss: 0.1253, G_Loss: 0.6931, net1_Loss: 0.0094, net2_Loss: 1.5219, \n",
            "Step [21800/100000], recon_Loss: 0.1252, G_Loss: 0.6828, net1_Loss: 0.0510, net2_Loss: 0.4965, \n",
            "Step [21900/100000], recon_Loss: 0.1299, G_Loss: 0.7008, net1_Loss: 0.0000, net2_Loss: 1.0466, \n",
            "Step [22000/100000], recon_Loss: 0.1229, G_Loss: 0.6931, net1_Loss: 0.0008, net2_Loss: 1.7998, \n",
            "Step [22100/100000], recon_Loss: 0.1290, G_Loss: 0.6739, net1_Loss: 0.0638, net2_Loss: 1.7652, \n",
            "Step [22200/100000], recon_Loss: 0.1251, G_Loss: 0.6806, net1_Loss: 0.0367, net2_Loss: 0.7215, \n",
            "Step [22300/100000], recon_Loss: 0.1251, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.9480, \n",
            "Step [22400/100000], recon_Loss: 0.1181, G_Loss: 0.6787, net1_Loss: 0.2731, net2_Loss: 0.2546, \n",
            "Step [22500/100000], recon_Loss: 0.1264, G_Loss: 0.6818, net1_Loss: 0.0434, net2_Loss: 0.3036, \n",
            "Step [22600/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0739, net2_Loss: 1.7236, \n",
            "Step [22700/100000], recon_Loss: 0.1309, G_Loss: 0.6931, net1_Loss: 0.0158, net2_Loss: 0.4896, \n",
            "Step [22800/100000], recon_Loss: 0.1259, G_Loss: 0.6973, net1_Loss: 0.0168, net2_Loss: 2.3477, \n",
            "Step [22900/100000], recon_Loss: 0.1279, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.5145, \n",
            "Step [23000/100000], recon_Loss: 0.1316, G_Loss: 0.6931, net1_Loss: 0.0269, net2_Loss: 1.0938, \n",
            "Step [23100/100000], recon_Loss: 0.1214, G_Loss: 0.6931, net1_Loss: 0.0541, net2_Loss: 1.0798, \n",
            "Step [23200/100000], recon_Loss: 0.1314, G_Loss: 0.6618, net1_Loss: 0.0748, net2_Loss: 2.2762, \n",
            "Step [23300/100000], recon_Loss: 0.1257, G_Loss: 0.6931, net1_Loss: 0.1010, net2_Loss: 1.1806, \n",
            "Step [23400/100000], recon_Loss: 0.1266, G_Loss: 0.6543, net1_Loss: 0.1339, net2_Loss: 0.1619, \n",
            "Step [23500/100000], recon_Loss: 0.1261, G_Loss: 0.6790, net1_Loss: 0.1892, net2_Loss: 0.6839, \n",
            "Step [23600/100000], recon_Loss: 0.1303, G_Loss: 0.6931, net1_Loss: 0.3147, net2_Loss: 0.4406, \n",
            "Step [23700/100000], recon_Loss: 0.1266, G_Loss: 0.6777, net1_Loss: 0.0860, net2_Loss: 1.1260, \n",
            "Step [23800/100000], recon_Loss: 0.1204, G_Loss: 0.6689, net1_Loss: 0.7670, net2_Loss: 0.3042, \n",
            "Step [23900/100000], recon_Loss: 0.1328, G_Loss: 0.6900, net1_Loss: 0.1563, net2_Loss: 1.6774, \n",
            "Step [24000/100000], recon_Loss: 0.1251, G_Loss: 0.6931, net1_Loss: 0.0124, net2_Loss: 1.3589, \n",
            "Step [24100/100000], recon_Loss: 0.1252, G_Loss: 0.6682, net1_Loss: 0.0672, net2_Loss: 0.7568, \n",
            "Step [24200/100000], recon_Loss: 0.1298, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 2.4282, \n",
            "Step [24300/100000], recon_Loss: 0.1226, G_Loss: 0.6931, net1_Loss: 0.0195, net2_Loss: 0.8839, \n",
            "Step [24400/100000], recon_Loss: 0.1284, G_Loss: 0.6612, net1_Loss: 0.0107, net2_Loss: 0.1178, \n",
            "Step [24500/100000], recon_Loss: 0.1247, G_Loss: 0.6758, net1_Loss: 0.0140, net2_Loss: 0.2415, \n",
            "Step [24600/100000], recon_Loss: 0.1250, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4005, \n",
            "Step [24700/100000], recon_Loss: 0.1179, G_Loss: 0.6705, net1_Loss: 0.0430, net2_Loss: 0.1083, \n",
            "Step [24800/100000], recon_Loss: 0.1265, G_Loss: 0.6775, net1_Loss: 0.0598, net2_Loss: 0.3181, \n",
            "Step [24900/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0382, net2_Loss: 0.9148, \n",
            "Step [25000/100000], recon_Loss: 0.1309, G_Loss: 0.6975, net1_Loss: 0.1013, net2_Loss: 0.2075, \n",
            "Step [25100/100000], recon_Loss: 0.1258, G_Loss: 0.6757, net1_Loss: 0.0000, net2_Loss: 0.5535, \n",
            "Step [25200/100000], recon_Loss: 0.1277, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5650, \n",
            "Step [25300/100000], recon_Loss: 0.1313, G_Loss: 0.6931, net1_Loss: 0.0697, net2_Loss: 1.5907, \n",
            "Step [25400/100000], recon_Loss: 0.1217, G_Loss: 0.6931, net1_Loss: 0.1563, net2_Loss: 0.6286, \n",
            "Step [25500/100000], recon_Loss: 0.1315, G_Loss: 0.6560, net1_Loss: 0.1166, net2_Loss: 1.2264, \n",
            "Step [25600/100000], recon_Loss: 0.1255, G_Loss: 0.6931, net1_Loss: 0.1847, net2_Loss: 1.3410, \n",
            "Step [25700/100000], recon_Loss: 0.1266, G_Loss: 0.6425, net1_Loss: 0.1225, net2_Loss: 0.3104, \n",
            "Step [25800/100000], recon_Loss: 0.1257, G_Loss: 0.6736, net1_Loss: 0.0758, net2_Loss: 0.5866, \n",
            "Step [25900/100000], recon_Loss: 0.1301, G_Loss: 0.6831, net1_Loss: 0.0639, net2_Loss: 0.7141, \n",
            "Step [26000/100000], recon_Loss: 0.1260, G_Loss: 0.6738, net1_Loss: 0.0157, net2_Loss: 0.5274, \n",
            "Step [26100/100000], recon_Loss: 0.1198, G_Loss: 0.6567, net1_Loss: 0.7907, net2_Loss: 1.1340, \n",
            "Step [26200/100000], recon_Loss: 0.1325, G_Loss: 0.6900, net1_Loss: 0.0415, net2_Loss: 0.4668, \n",
            "Step [26300/100000], recon_Loss: 0.1258, G_Loss: 0.6931, net1_Loss: 0.0168, net2_Loss: 1.1963, \n",
            "Step [26400/100000], recon_Loss: 0.1251, G_Loss: 0.6605, net1_Loss: 0.0927, net2_Loss: 0.9029, \n",
            "Step [26500/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5184, \n",
            "Step [26600/100000], recon_Loss: 0.1226, G_Loss: 0.6931, net1_Loss: 0.0031, net2_Loss: 0.6782, \n",
            "Step [26700/100000], recon_Loss: 0.1286, G_Loss: 0.6770, net1_Loss: 0.0504, net2_Loss: 0.8504, \n",
            "Step [26800/100000], recon_Loss: 0.1250, G_Loss: 0.6779, net1_Loss: 0.1154, net2_Loss: 0.6365, \n",
            "Step [26900/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5174, \n",
            "Step [27000/100000], recon_Loss: 0.1179, G_Loss: 0.6565, net1_Loss: 0.1843, net2_Loss: 0.9297, \n",
            "Step [27100/100000], recon_Loss: 0.1264, G_Loss: 0.6777, net1_Loss: 0.0265, net2_Loss: 1.4910, \n",
            "Step [27200/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.3014, net2_Loss: 0.8493, \n",
            "Step [27300/100000], recon_Loss: 0.1309, G_Loss: 0.6931, net1_Loss: 0.0247, net2_Loss: 0.2894, \n",
            "Step [27400/100000], recon_Loss: 0.1257, G_Loss: 0.6842, net1_Loss: 0.0135, net2_Loss: 0.5097, \n",
            "Step [27500/100000], recon_Loss: 0.1277, G_Loss: 0.7011, net1_Loss: 0.0000, net2_Loss: 0.6861, \n",
            "Step [27600/100000], recon_Loss: 0.1314, G_Loss: 0.6931, net1_Loss: 0.1112, net2_Loss: 0.5636, \n",
            "Step [27700/100000], recon_Loss: 0.1216, G_Loss: 0.6931, net1_Loss: 0.1037, net2_Loss: 0.1015, \n",
            "Step [27800/100000], recon_Loss: 0.1314, G_Loss: 0.6578, net1_Loss: 0.1071, net2_Loss: 0.8910, \n",
            "Step [27900/100000], recon_Loss: 0.1259, G_Loss: 0.6933, net1_Loss: 0.9672, net2_Loss: 0.4449, \n",
            "Step [28000/100000], recon_Loss: 0.1266, G_Loss: 0.6427, net1_Loss: 0.5565, net2_Loss: 1.4141, \n",
            "Step [28100/100000], recon_Loss: 0.1261, G_Loss: 0.6727, net1_Loss: 0.0619, net2_Loss: 0.7476, \n",
            "Step [28200/100000], recon_Loss: 0.1303, G_Loss: 0.6784, net1_Loss: 0.0116, net2_Loss: 0.2521, \n",
            "Step [28300/100000], recon_Loss: 0.1257, G_Loss: 0.6752, net1_Loss: 0.0935, net2_Loss: 0.4784, \n",
            "Step [28400/100000], recon_Loss: 0.1187, G_Loss: 0.6473, net1_Loss: 0.2035, net2_Loss: 0.5140, \n",
            "Step [28500/100000], recon_Loss: 0.1323, G_Loss: 0.6982, net1_Loss: 0.0823, net2_Loss: 0.8651, \n",
            "Step [28600/100000], recon_Loss: 0.1254, G_Loss: 0.6931, net1_Loss: 0.0219, net2_Loss: 1.4917, \n",
            "Step [28700/100000], recon_Loss: 0.1254, G_Loss: 0.6603, net1_Loss: 0.0426, net2_Loss: 1.2397, \n",
            "Step [28800/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5669, \n",
            "Step [28900/100000], recon_Loss: 0.1228, G_Loss: 0.6931, net1_Loss: 0.0716, net2_Loss: 1.5628, \n",
            "Step [29000/100000], recon_Loss: 0.1285, G_Loss: 0.6627, net1_Loss: 0.0623, net2_Loss: 0.6609, \n",
            "Step [29100/100000], recon_Loss: 0.1250, G_Loss: 0.6775, net1_Loss: 0.0847, net2_Loss: 1.8190, \n",
            "Step [29200/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4310, \n",
            "Step [29300/100000], recon_Loss: 0.1178, G_Loss: 0.6395, net1_Loss: 0.1059, net2_Loss: 0.3118, \n",
            "Step [29400/100000], recon_Loss: 0.1264, G_Loss: 0.6817, net1_Loss: 0.0373, net2_Loss: 0.3680, \n",
            "Step [29500/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.1869, net2_Loss: 1.3789, \n",
            "Step [29600/100000], recon_Loss: 0.1309, G_Loss: 0.6931, net1_Loss: 0.0359, net2_Loss: 0.7287, \n",
            "Step [29700/100000], recon_Loss: 0.1259, G_Loss: 0.6787, net1_Loss: 0.0004, net2_Loss: 0.5219, \n",
            "Step [29800/100000], recon_Loss: 0.1276, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4922, \n",
            "Step [29900/100000], recon_Loss: 0.1312, G_Loss: 0.6931, net1_Loss: 0.0988, net2_Loss: 0.4748, \n",
            "Step [30000/100000], recon_Loss: 0.1213, G_Loss: 0.6943, net1_Loss: 0.0760, net2_Loss: 0.7771, \n",
            "Step [30100/100000], recon_Loss: 0.1315, G_Loss: 0.6569, net1_Loss: 0.0443, net2_Loss: 1.4915, \n",
            "Step [30200/100000], recon_Loss: 0.1259, G_Loss: 0.6931, net1_Loss: 0.2666, net2_Loss: 0.5587, \n",
            "Step [30300/100000], recon_Loss: 0.1268, G_Loss: 0.6502, net1_Loss: 1.0551, net2_Loss: 0.7415, \n",
            "Step [30400/100000], recon_Loss: 0.1260, G_Loss: 0.6768, net1_Loss: 0.0845, net2_Loss: 1.3574, \n",
            "Step [30500/100000], recon_Loss: 0.1304, G_Loss: 0.6763, net1_Loss: 0.0516, net2_Loss: 0.5092, \n",
            "Step [30600/100000], recon_Loss: 0.1255, G_Loss: 0.6781, net1_Loss: 0.0324, net2_Loss: 1.2911, \n",
            "Step [30700/100000], recon_Loss: 0.1193, G_Loss: 0.6712, net1_Loss: 0.4365, net2_Loss: 0.4421, \n",
            "Step [30800/100000], recon_Loss: 0.1322, G_Loss: 0.6819, net1_Loss: 0.0847, net2_Loss: 1.1591, \n",
            "Step [30900/100000], recon_Loss: 0.1252, G_Loss: 0.6931, net1_Loss: 0.0594, net2_Loss: 3.1684, \n",
            "Step [31000/100000], recon_Loss: 0.1250, G_Loss: 0.6568, net1_Loss: 0.1580, net2_Loss: 1.0547, \n",
            "Step [31100/100000], recon_Loss: 0.1297, G_Loss: 0.7014, net1_Loss: 0.0000, net2_Loss: 0.6760, \n",
            "Step [31200/100000], recon_Loss: 0.1225, G_Loss: 0.6931, net1_Loss: 0.0840, net2_Loss: 0.6986, \n",
            "Step [31300/100000], recon_Loss: 0.1286, G_Loss: 0.6566, net1_Loss: 0.1021, net2_Loss: 0.3507, \n",
            "Step [31400/100000], recon_Loss: 0.1252, G_Loss: 0.6778, net1_Loss: 0.1114, net2_Loss: 0.2503, \n",
            "Step [31500/100000], recon_Loss: 0.1249, G_Loss: 0.6953, net1_Loss: 0.0000, net2_Loss: 0.5416, \n",
            "Step [31600/100000], recon_Loss: 0.1180, G_Loss: 0.6443, net1_Loss: 0.1488, net2_Loss: 0.2517, \n",
            "Step [31700/100000], recon_Loss: 0.1264, G_Loss: 0.6834, net1_Loss: 0.0391, net2_Loss: 1.2408, \n",
            "Step [31800/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0396, net2_Loss: 0.9103, \n",
            "Step [31900/100000], recon_Loss: 0.1307, G_Loss: 0.6983, net1_Loss: 0.0673, net2_Loss: 0.4770, \n",
            "Step [32000/100000], recon_Loss: 0.1256, G_Loss: 0.6777, net1_Loss: 0.0001, net2_Loss: 0.2272, \n",
            "Step [32100/100000], recon_Loss: 0.1276, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.0714, \n",
            "Step [32200/100000], recon_Loss: 0.1310, G_Loss: 0.6931, net1_Loss: 0.0086, net2_Loss: 1.8973, \n",
            "Step [32300/100000], recon_Loss: 0.1214, G_Loss: 0.6931, net1_Loss: 0.0977, net2_Loss: 0.2421, \n",
            "Step [32400/100000], recon_Loss: 0.1313, G_Loss: 0.6542, net1_Loss: 0.0389, net2_Loss: 1.0547, \n",
            "Step [32500/100000], recon_Loss: 0.1259, G_Loss: 0.6931, net1_Loss: 0.2945, net2_Loss: 0.6845, \n",
            "Step [32600/100000], recon_Loss: 0.1267, G_Loss: 0.6428, net1_Loss: 0.0765, net2_Loss: 0.3381, \n",
            "Step [32700/100000], recon_Loss: 0.1260, G_Loss: 0.6857, net1_Loss: 0.5582, net2_Loss: 3.0071, \n",
            "Step [32800/100000], recon_Loss: 0.1302, G_Loss: 0.6819, net1_Loss: 0.0513, net2_Loss: 0.6712, \n",
            "Step [32900/100000], recon_Loss: 0.1255, G_Loss: 0.6741, net1_Loss: 0.1067, net2_Loss: 0.6934, \n",
            "Step [33000/100000], recon_Loss: 0.1187, G_Loss: 0.6589, net1_Loss: 0.2438, net2_Loss: 0.6489, \n",
            "Step [33100/100000], recon_Loss: 0.1321, G_Loss: 0.6846, net1_Loss: 0.0331, net2_Loss: 0.4781, \n",
            "Step [33200/100000], recon_Loss: 0.1250, G_Loss: 0.6931, net1_Loss: 0.0516, net2_Loss: 0.3446, \n",
            "Step [33300/100000], recon_Loss: 0.1248, G_Loss: 0.6549, net1_Loss: 0.1005, net2_Loss: 0.2735, \n",
            "Step [33400/100000], recon_Loss: 0.1296, G_Loss: 0.6997, net1_Loss: 0.0000, net2_Loss: 0.2679, \n",
            "Step [33500/100000], recon_Loss: 0.1226, G_Loss: 0.6931, net1_Loss: 0.0073, net2_Loss: 1.6073, \n",
            "Step [33600/100000], recon_Loss: 0.1287, G_Loss: 0.6599, net1_Loss: 0.0548, net2_Loss: 2.1027, \n",
            "Step [33700/100000], recon_Loss: 0.1250, G_Loss: 0.6744, net1_Loss: 0.1404, net2_Loss: 2.0482, \n",
            "Step [33800/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5792, \n",
            "Step [33900/100000], recon_Loss: 0.1179, G_Loss: 0.6389, net1_Loss: 0.0811, net2_Loss: 0.2890, \n",
            "Step [34000/100000], recon_Loss: 0.1268, G_Loss: 0.6756, net1_Loss: 0.0558, net2_Loss: 0.4954, \n",
            "Step [34100/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0737, net2_Loss: 0.5620, \n",
            "Step [34200/100000], recon_Loss: 0.1307, G_Loss: 0.6935, net1_Loss: 0.0124, net2_Loss: 1.7751, \n",
            "Step [34300/100000], recon_Loss: 0.1255, G_Loss: 0.6923, net1_Loss: 0.0047, net2_Loss: 0.6894, \n",
            "Step [34400/100000], recon_Loss: 0.1276, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3566, \n",
            "Step [34500/100000], recon_Loss: 0.1309, G_Loss: 0.6931, net1_Loss: 0.0195, net2_Loss: 0.3138, \n",
            "Step [34600/100000], recon_Loss: 0.1212, G_Loss: 0.6960, net1_Loss: 0.0388, net2_Loss: 0.1270, \n",
            "Step [34700/100000], recon_Loss: 0.1311, G_Loss: 0.6592, net1_Loss: 0.1067, net2_Loss: 0.3371, \n",
            "Step [34800/100000], recon_Loss: 0.1252, G_Loss: 0.6931, net1_Loss: 0.1840, net2_Loss: 0.2007, \n",
            "Step [34900/100000], recon_Loss: 0.1266, G_Loss: 0.6428, net1_Loss: 0.2269, net2_Loss: 0.2959, \n",
            "Step [35000/100000], recon_Loss: 0.1265, G_Loss: 0.6727, net1_Loss: 0.1946, net2_Loss: 1.7337, \n",
            "Step [35100/100000], recon_Loss: 0.1306, G_Loss: 0.6755, net1_Loss: 0.0482, net2_Loss: 3.1484, \n",
            "Step [35200/100000], recon_Loss: 0.1258, G_Loss: 0.6744, net1_Loss: 0.0624, net2_Loss: 2.1931, \n",
            "Step [35300/100000], recon_Loss: 0.1189, G_Loss: 0.6613, net1_Loss: 0.7623, net2_Loss: 0.3891, \n",
            "Step [35400/100000], recon_Loss: 0.1321, G_Loss: 0.6770, net1_Loss: 0.0581, net2_Loss: 0.4304, \n",
            "Step [35500/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0303, net2_Loss: 0.3120, \n",
            "Step [35600/100000], recon_Loss: 0.1247, G_Loss: 0.6652, net1_Loss: 0.0184, net2_Loss: 0.4430, \n",
            "Step [35700/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.6871, \n",
            "Step [35800/100000], recon_Loss: 0.1225, G_Loss: 0.6931, net1_Loss: 0.0551, net2_Loss: 0.3308, \n",
            "Step [35900/100000], recon_Loss: 0.1285, G_Loss: 0.6598, net1_Loss: 0.1368, net2_Loss: 0.5590, \n",
            "Step [36000/100000], recon_Loss: 0.1255, G_Loss: 0.6764, net1_Loss: 0.6874, net2_Loss: 1.2089, \n",
            "Step [36100/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5134, \n",
            "Step [36200/100000], recon_Loss: 0.1181, G_Loss: 0.6333, net1_Loss: 0.3043, net2_Loss: 0.1751, \n",
            "Step [36300/100000], recon_Loss: 0.1260, G_Loss: 0.6773, net1_Loss: 0.0713, net2_Loss: 0.5771, \n",
            "Step [36400/100000], recon_Loss: 0.1292, G_Loss: 0.6883, net1_Loss: 0.0289, net2_Loss: 0.6228, \n",
            "Step [36500/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0137, net2_Loss: 0.6923, \n",
            "Step [36600/100000], recon_Loss: 0.1256, G_Loss: 0.6881, net1_Loss: 0.0214, net2_Loss: 4.1064, \n",
            "Step [36700/100000], recon_Loss: 0.1275, G_Loss: 0.7011, net1_Loss: 0.0000, net2_Loss: 1.1426, \n",
            "Step [36800/100000], recon_Loss: 0.1308, G_Loss: 0.6931, net1_Loss: 0.0076, net2_Loss: 0.8952, \n",
            "Step [36900/100000], recon_Loss: 0.1212, G_Loss: 0.6931, net1_Loss: 0.0747, net2_Loss: 0.2414, \n",
            "Step [37000/100000], recon_Loss: 0.1313, G_Loss: 0.6551, net1_Loss: 0.0033, net2_Loss: 0.4311, \n",
            "Step [37100/100000], recon_Loss: 0.1254, G_Loss: 0.6931, net1_Loss: 0.1476, net2_Loss: 0.2443, \n",
            "Step [37200/100000], recon_Loss: 0.1265, G_Loss: 0.6394, net1_Loss: 0.1490, net2_Loss: 0.4638, \n",
            "Step [37300/100000], recon_Loss: 0.1256, G_Loss: 0.6726, net1_Loss: 0.1006, net2_Loss: 1.7688, \n",
            "Step [37400/100000], recon_Loss: 0.1303, G_Loss: 0.6764, net1_Loss: 0.0209, net2_Loss: 0.4046, \n",
            "Step [37500/100000], recon_Loss: 0.1258, G_Loss: 0.6730, net1_Loss: 0.1518, net2_Loss: 0.4731, \n",
            "Step [37600/100000], recon_Loss: 0.1189, G_Loss: 0.6594, net1_Loss: 0.3775, net2_Loss: 0.5226, \n",
            "Step [37700/100000], recon_Loss: 0.1322, G_Loss: 0.6787, net1_Loss: 0.0530, net2_Loss: 0.7954, \n",
            "Step [37800/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0603, net2_Loss: 0.4233, \n",
            "Step [37900/100000], recon_Loss: 0.1248, G_Loss: 0.6425, net1_Loss: 0.1193, net2_Loss: 0.2284, \n",
            "Step [38000/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2300, \n",
            "Step [38100/100000], recon_Loss: 0.1225, G_Loss: 0.6931, net1_Loss: 0.0058, net2_Loss: 0.3326, \n",
            "Step [38200/100000], recon_Loss: 0.1284, G_Loss: 0.6558, net1_Loss: 0.0621, net2_Loss: 0.4017, \n",
            "Step [38300/100000], recon_Loss: 0.1250, G_Loss: 0.6859, net1_Loss: 0.5105, net2_Loss: 2.8125, \n",
            "Step [38400/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 3.1420, \n",
            "Step [38500/100000], recon_Loss: 0.1180, G_Loss: 0.6268, net1_Loss: 0.2943, net2_Loss: 0.1641, \n",
            "Step [38600/100000], recon_Loss: 0.1260, G_Loss: 0.6750, net1_Loss: 0.1122, net2_Loss: 0.2709, \n",
            "Step [38700/100000], recon_Loss: 0.1292, G_Loss: 0.6875, net1_Loss: 0.0582, net2_Loss: 0.5587, \n",
            "Step [38800/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0356, net2_Loss: 0.1755, \n",
            "Step [38900/100000], recon_Loss: 0.1255, G_Loss: 0.6840, net1_Loss: 0.0016, net2_Loss: 0.3200, \n",
            "Step [39000/100000], recon_Loss: 0.1276, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3109, \n",
            "Step [39100/100000], recon_Loss: 0.1310, G_Loss: 0.6931, net1_Loss: 0.0569, net2_Loss: 0.5093, \n",
            "Step [39200/100000], recon_Loss: 0.1214, G_Loss: 0.6931, net1_Loss: 0.6553, net2_Loss: 0.1517, \n",
            "Step [39300/100000], recon_Loss: 0.1316, G_Loss: 0.6587, net1_Loss: 0.2067, net2_Loss: 6.7850, \n",
            "Step [39400/100000], recon_Loss: 0.1253, G_Loss: 0.6931, net1_Loss: 0.2574, net2_Loss: 0.3684, \n",
            "Step [39500/100000], recon_Loss: 0.1265, G_Loss: 0.6357, net1_Loss: 2.1625, net2_Loss: 2.6502, \n",
            "Step [39600/100000], recon_Loss: 0.1258, G_Loss: 0.6724, net1_Loss: 0.2189, net2_Loss: 1.6619, \n",
            "Step [39700/100000], recon_Loss: 0.1299, G_Loss: 0.6784, net1_Loss: 0.0188, net2_Loss: 0.4728, \n",
            "Step [39800/100000], recon_Loss: 0.1254, G_Loss: 0.6756, net1_Loss: 0.0041, net2_Loss: 1.4664, \n",
            "Step [39900/100000], recon_Loss: 0.1186, G_Loss: 0.6678, net1_Loss: 0.0882, net2_Loss: 0.2869, \n",
            "Step [40000/100000], recon_Loss: 0.1319, G_Loss: 0.6808, net1_Loss: 0.0058, net2_Loss: 0.4458, \n",
            "Step [40100/100000], recon_Loss: 0.1250, G_Loss: 0.6931, net1_Loss: 0.0008, net2_Loss: 0.9591, \n",
            "Step [40200/100000], recon_Loss: 0.1247, G_Loss: 0.6497, net1_Loss: 0.0089, net2_Loss: 0.1157, \n",
            "Step [40300/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2813, \n",
            "Step [40400/100000], recon_Loss: 0.1223, G_Loss: 0.6931, net1_Loss: 0.0005, net2_Loss: 0.0564, \n",
            "Step [40500/100000], recon_Loss: 0.1283, G_Loss: 0.6544, net1_Loss: 0.0495, net2_Loss: 0.0754, \n",
            "Step [40600/100000], recon_Loss: 0.1246, G_Loss: 0.6741, net1_Loss: 0.0038, net2_Loss: 0.1148, \n",
            "Step [40700/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0599, \n",
            "Step [40800/100000], recon_Loss: 0.1178, G_Loss: 0.6312, net1_Loss: 0.0088, net2_Loss: 0.0293, \n",
            "Step [40900/100000], recon_Loss: 0.1260, G_Loss: 0.6812, net1_Loss: 0.0063, net2_Loss: 0.0454, \n",
            "Step [41000/100000], recon_Loss: 0.1291, G_Loss: 0.6830, net1_Loss: 0.0040, net2_Loss: 0.7326, \n",
            "Step [41100/100000], recon_Loss: 0.1304, G_Loss: 0.6931, net1_Loss: 0.0065, net2_Loss: 1.5648, \n",
            "Step [41200/100000], recon_Loss: 0.1254, G_Loss: 0.6775, net1_Loss: 0.0133, net2_Loss: 1.3356, \n",
            "Step [41300/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2549, \n",
            "Step [41400/100000], recon_Loss: 0.1309, G_Loss: 0.6856, net1_Loss: 0.1774, net2_Loss: 0.3662, \n",
            "Step [41500/100000], recon_Loss: 0.1211, G_Loss: 0.6931, net1_Loss: 0.1890, net2_Loss: 0.0673, \n",
            "Step [41600/100000], recon_Loss: 0.1311, G_Loss: 0.6531, net1_Loss: 0.0378, net2_Loss: 0.1325, \n",
            "Step [41700/100000], recon_Loss: 0.1252, G_Loss: 0.6931, net1_Loss: 0.0062, net2_Loss: 0.1934, \n",
            "Step [41800/100000], recon_Loss: 0.1264, G_Loss: 0.6357, net1_Loss: 0.0064, net2_Loss: 0.0182, \n",
            "Step [41900/100000], recon_Loss: 0.1254, G_Loss: 0.6720, net1_Loss: 0.0239, net2_Loss: 1.0705, \n",
            "Step [42000/100000], recon_Loss: 0.1299, G_Loss: 0.6735, net1_Loss: 0.0030, net2_Loss: 0.2225, \n",
            "Step [42100/100000], recon_Loss: 0.1253, G_Loss: 0.6730, net1_Loss: 0.0095, net2_Loss: 1.2454, \n",
            "Step [42200/100000], recon_Loss: 0.1188, G_Loss: 0.6523, net1_Loss: 0.0377, net2_Loss: 1.9440, \n",
            "Step [42300/100000], recon_Loss: 0.1321, G_Loss: 0.6782, net1_Loss: 0.0027, net2_Loss: 1.3919, \n",
            "Step [42400/100000], recon_Loss: 0.1250, G_Loss: 0.6931, net1_Loss: 0.0438, net2_Loss: 0.9890, \n",
            "Step [42500/100000], recon_Loss: 0.1251, G_Loss: 0.6456, net1_Loss: 0.1233, net2_Loss: 0.2652, \n",
            "Step [42600/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3286, \n",
            "Step [42700/100000], recon_Loss: 0.1223, G_Loss: 0.6931, net1_Loss: 0.0020, net2_Loss: 0.3895, \n",
            "Step [42800/100000], recon_Loss: 0.1283, G_Loss: 0.6530, net1_Loss: 0.1022, net2_Loss: 0.1257, \n",
            "Step [42900/100000], recon_Loss: 0.1246, G_Loss: 0.6737, net1_Loss: 0.0996, net2_Loss: 0.1109, \n",
            "Step [43000/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.6138, \n",
            "Step [43100/100000], recon_Loss: 0.1178, G_Loss: 0.6161, net1_Loss: 0.0834, net2_Loss: 0.0257, \n",
            "Step [43200/100000], recon_Loss: 0.1261, G_Loss: 0.6748, net1_Loss: 0.0553, net2_Loss: 0.2318, \n",
            "Step [43300/100000], recon_Loss: 0.1291, G_Loss: 0.6819, net1_Loss: 0.0345, net2_Loss: 0.8948, \n",
            "Step [43400/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0044, net2_Loss: 0.9013, \n",
            "Step [43500/100000], recon_Loss: 0.1256, G_Loss: 0.6801, net1_Loss: 0.0013, net2_Loss: 1.7582, \n",
            "Step [43600/100000], recon_Loss: 0.1275, G_Loss: 0.6984, net1_Loss: 0.0000, net2_Loss: 0.6659, \n",
            "Step [43700/100000], recon_Loss: 0.1310, G_Loss: 0.6803, net1_Loss: 0.0698, net2_Loss: 0.5639, \n",
            "Step [43800/100000], recon_Loss: 0.1213, G_Loss: 0.6933, net1_Loss: 0.1699, net2_Loss: 0.3175, \n",
            "Step [43900/100000], recon_Loss: 0.1311, G_Loss: 0.6558, net1_Loss: 0.0626, net2_Loss: 0.4566, \n",
            "Step [44000/100000], recon_Loss: 0.1253, G_Loss: 0.6906, net1_Loss: 0.2241, net2_Loss: 0.1596, \n",
            "Step [44100/100000], recon_Loss: 0.1264, G_Loss: 0.6359, net1_Loss: 0.1198, net2_Loss: 0.1397, \n",
            "Step [44200/100000], recon_Loss: 0.1257, G_Loss: 0.6725, net1_Loss: 0.1750, net2_Loss: 0.4140, \n",
            "Step [44300/100000], recon_Loss: 0.1299, G_Loss: 0.6735, net1_Loss: 0.0357, net2_Loss: 0.5452, \n",
            "Step [44400/100000], recon_Loss: 0.1256, G_Loss: 0.6756, net1_Loss: 0.0079, net2_Loss: 0.5845, \n",
            "Step [44500/100000], recon_Loss: 0.1187, G_Loss: 0.6477, net1_Loss: 0.0643, net2_Loss: 0.1662, \n",
            "Step [44600/100000], recon_Loss: 0.1322, G_Loss: 0.6747, net1_Loss: 0.0187, net2_Loss: 0.1932, \n",
            "Step [44700/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.2396, net2_Loss: 0.3590, \n",
            "Step [44800/100000], recon_Loss: 0.1247, G_Loss: 0.6476, net1_Loss: 0.0841, net2_Loss: 2.3155, \n",
            "Step [44900/100000], recon_Loss: 0.1297, G_Loss: 0.6941, net1_Loss: 0.0000, net2_Loss: 0.7917, \n",
            "Step [45000/100000], recon_Loss: 0.1226, G_Loss: 0.6932, net1_Loss: 0.0044, net2_Loss: 0.3015, \n",
            "Step [45100/100000], recon_Loss: 0.1283, G_Loss: 0.6610, net1_Loss: 0.1113, net2_Loss: 0.1658, \n",
            "Step [45200/100000], recon_Loss: 0.1247, G_Loss: 0.6730, net1_Loss: 0.0301, net2_Loss: 0.0750, \n",
            "Step [45300/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.7853, \n",
            "Step [45400/100000], recon_Loss: 0.1178, G_Loss: 0.5887, net1_Loss: 0.0652, net2_Loss: 0.5954, \n",
            "Step [45500/100000], recon_Loss: 0.1278, G_Loss: 0.6743, net1_Loss: 0.3362, net2_Loss: 1.2210, \n",
            "Step [45600/100000], recon_Loss: 0.1292, G_Loss: 0.6785, net1_Loss: 0.2884, net2_Loss: 1.1130, \n",
            "Step [45700/100000], recon_Loss: 0.1305, G_Loss: 0.6939, net1_Loss: 0.0816, net2_Loss: 0.5223, \n",
            "Step [45800/100000], recon_Loss: 0.1255, G_Loss: 0.6759, net1_Loss: 0.0027, net2_Loss: 0.2676, \n",
            "Step [45900/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3571, \n",
            "Step [46000/100000], recon_Loss: 0.1308, G_Loss: 0.6771, net1_Loss: 0.0111, net2_Loss: 0.3354, \n",
            "Step [46100/100000], recon_Loss: 0.1212, G_Loss: 0.6938, net1_Loss: 0.0282, net2_Loss: 0.0376, \n",
            "Step [46200/100000], recon_Loss: 0.1311, G_Loss: 0.6529, net1_Loss: 0.0045, net2_Loss: 0.4461, \n",
            "Step [46300/100000], recon_Loss: 0.1252, G_Loss: 0.6931, net1_Loss: 0.0162, net2_Loss: 0.6107, \n",
            "Step [46400/100000], recon_Loss: 0.1265, G_Loss: 0.6341, net1_Loss: 0.0131, net2_Loss: 0.1372, \n",
            "Step [46500/100000], recon_Loss: 0.1257, G_Loss: 0.6721, net1_Loss: 0.3307, net2_Loss: 2.5690, \n",
            "Step [46600/100000], recon_Loss: 0.1300, G_Loss: 0.6752, net1_Loss: 0.2149, net2_Loss: 0.5291, \n",
            "Step [46700/100000], recon_Loss: 0.1253, G_Loss: 0.6756, net1_Loss: 0.0223, net2_Loss: 0.1779, \n",
            "Step [46800/100000], recon_Loss: 0.1186, G_Loss: 0.6418, net1_Loss: 0.5277, net2_Loss: 0.1577, \n",
            "Step [46900/100000], recon_Loss: 0.1320, G_Loss: 0.6754, net1_Loss: 0.0036, net2_Loss: 0.2234, \n",
            "Step [47000/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0245, net2_Loss: 0.6619, \n",
            "Step [47100/100000], recon_Loss: 0.1248, G_Loss: 0.6431, net1_Loss: 0.0371, net2_Loss: 1.4772, \n",
            "Step [47200/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 2.2153, \n",
            "Step [47300/100000], recon_Loss: 0.1226, G_Loss: 0.6957, net1_Loss: 0.0325, net2_Loss: 0.3632, \n",
            "Step [47400/100000], recon_Loss: 0.1284, G_Loss: 0.6566, net1_Loss: 0.0584, net2_Loss: 0.2122, \n",
            "Step [47500/100000], recon_Loss: 0.1247, G_Loss: 0.6742, net1_Loss: 0.0377, net2_Loss: 0.2111, \n",
            "Step [47600/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4175, \n",
            "Step [47700/100000], recon_Loss: 0.1179, G_Loss: 0.5832, net1_Loss: 0.2253, net2_Loss: 0.1780, \n",
            "Step [47800/100000], recon_Loss: 0.1261, G_Loss: 0.6756, net1_Loss: 0.1993, net2_Loss: 0.2591, \n",
            "Step [47900/100000], recon_Loss: 0.1291, G_Loss: 0.6761, net1_Loss: 0.2615, net2_Loss: 0.8578, \n",
            "Step [48000/100000], recon_Loss: 0.1307, G_Loss: 0.6952, net1_Loss: 0.0524, net2_Loss: 0.1289, \n",
            "Step [48100/100000], recon_Loss: 0.1256, G_Loss: 0.6755, net1_Loss: 0.0758, net2_Loss: 0.1365, \n",
            "Step [48200/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1957, \n",
            "Step [48300/100000], recon_Loss: 0.1310, G_Loss: 0.6780, net1_Loss: 0.0896, net2_Loss: 0.4559, \n",
            "Step [48400/100000], recon_Loss: 0.1212, G_Loss: 0.6931, net1_Loss: 0.1751, net2_Loss: 0.3154, \n",
            "Step [48500/100000], recon_Loss: 0.1310, G_Loss: 0.6531, net1_Loss: 0.0875, net2_Loss: 0.6689, \n",
            "Step [48600/100000], recon_Loss: 0.1253, G_Loss: 0.6803, net1_Loss: 0.0412, net2_Loss: 1.0236, \n",
            "Step [48700/100000], recon_Loss: 0.1266, G_Loss: 0.6370, net1_Loss: 0.0739, net2_Loss: 0.6132, \n",
            "Step [48800/100000], recon_Loss: 0.1258, G_Loss: 0.6809, net1_Loss: 0.2259, net2_Loss: 0.4173, \n",
            "Step [48900/100000], recon_Loss: 0.1299, G_Loss: 0.6734, net1_Loss: 0.0530, net2_Loss: 0.3941, \n",
            "Step [49000/100000], recon_Loss: 0.1255, G_Loss: 0.6737, net1_Loss: 0.0800, net2_Loss: 0.5673, \n",
            "Step [49100/100000], recon_Loss: 0.1188, G_Loss: 0.6409, net1_Loss: 0.0765, net2_Loss: 0.3345, \n",
            "Step [49200/100000], recon_Loss: 0.1319, G_Loss: 0.6759, net1_Loss: 0.0009, net2_Loss: 1.2582, \n",
            "Step [49300/100000], recon_Loss: 0.1252, G_Loss: 0.6931, net1_Loss: 0.0145, net2_Loss: 1.5125, \n",
            "Step [49400/100000], recon_Loss: 0.1250, G_Loss: 0.6459, net1_Loss: 0.0920, net2_Loss: 0.8237, \n",
            "Step [49500/100000], recon_Loss: 0.1295, G_Loss: 0.6933, net1_Loss: 0.0000, net2_Loss: 0.3637, \n",
            "Step [49600/100000], recon_Loss: 0.1223, G_Loss: 0.6845, net1_Loss: 0.0348, net2_Loss: 0.6383, \n",
            "Step [49700/100000], recon_Loss: 0.1283, G_Loss: 0.6521, net1_Loss: 0.0391, net2_Loss: 0.0803, \n",
            "Step [49800/100000], recon_Loss: 0.1247, G_Loss: 0.6738, net1_Loss: 0.4823, net2_Loss: 0.1819, \n",
            "Step [49900/100000], recon_Loss: 0.1248, G_Loss: 0.6943, net1_Loss: 0.0000, net2_Loss: 1.3763, \n",
            "Step [50000/100000], recon_Loss: 0.1179, G_Loss: 0.5731, net1_Loss: 0.5131, net2_Loss: 0.4845, \n",
            "Step [50100/100000], recon_Loss: 0.1261, G_Loss: 0.6739, net1_Loss: 0.3785, net2_Loss: 1.0364, \n",
            "Step [50200/100000], recon_Loss: 0.1290, G_Loss: 0.6778, net1_Loss: 0.0310, net2_Loss: 0.3501, \n",
            "Step [50300/100000], recon_Loss: 0.1306, G_Loss: 0.6944, net1_Loss: 0.0670, net2_Loss: 0.5147, \n",
            "Step [50400/100000], recon_Loss: 0.1256, G_Loss: 0.6842, net1_Loss: 0.0089, net2_Loss: 0.8354, \n",
            "Step [50500/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5032, \n",
            "Step [50600/100000], recon_Loss: 0.1310, G_Loss: 0.6768, net1_Loss: 0.2042, net2_Loss: 0.3502, \n",
            "Step [50700/100000], recon_Loss: 0.1212, G_Loss: 0.6931, net1_Loss: 0.1394, net2_Loss: 0.1164, \n",
            "Step [50800/100000], recon_Loss: 0.1311, G_Loss: 0.6547, net1_Loss: 0.0360, net2_Loss: 0.2752, \n",
            "Step [50900/100000], recon_Loss: 0.1252, G_Loss: 0.6829, net1_Loss: 0.0658, net2_Loss: 0.3520, \n",
            "Step [51000/100000], recon_Loss: 0.1264, G_Loss: 0.6359, net1_Loss: 0.0786, net2_Loss: 1.0546, \n",
            "Step [51100/100000], recon_Loss: 0.1255, G_Loss: 0.6727, net1_Loss: 0.1364, net2_Loss: 0.3298, \n",
            "Step [51200/100000], recon_Loss: 0.1299, G_Loss: 0.6746, net1_Loss: 0.3388, net2_Loss: 0.1754, \n",
            "Step [51300/100000], recon_Loss: 0.1257, G_Loss: 0.6735, net1_Loss: 0.0639, net2_Loss: 0.3656, \n",
            "Step [51400/100000], recon_Loss: 0.1190, G_Loss: 0.6410, net1_Loss: 0.4299, net2_Loss: 0.2981, \n",
            "Step [51500/100000], recon_Loss: 0.1320, G_Loss: 0.6733, net1_Loss: 0.0158, net2_Loss: 1.1813, \n",
            "Step [51600/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0272, net2_Loss: 0.2928, \n",
            "Step [51700/100000], recon_Loss: 0.1248, G_Loss: 0.6518, net1_Loss: 0.0444, net2_Loss: 0.2033, \n",
            "Step [51800/100000], recon_Loss: 0.1295, G_Loss: 0.6945, net1_Loss: 0.0000, net2_Loss: 0.4839, \n",
            "Step [51900/100000], recon_Loss: 0.1224, G_Loss: 0.6909, net1_Loss: 0.0012, net2_Loss: 0.8195, \n",
            "Step [52000/100000], recon_Loss: 0.1284, G_Loss: 0.6519, net1_Loss: 0.1484, net2_Loss: 0.2762, \n",
            "Step [52100/100000], recon_Loss: 0.1247, G_Loss: 0.6746, net1_Loss: 0.3452, net2_Loss: 0.7819, \n",
            "Step [52200/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2691, \n",
            "Step [52300/100000], recon_Loss: 0.1177, G_Loss: 0.5769, net1_Loss: 0.0968, net2_Loss: 0.2197, \n",
            "Step [52400/100000], recon_Loss: 0.1260, G_Loss: 0.6734, net1_Loss: 0.0581, net2_Loss: 0.8390, \n",
            "Step [52500/100000], recon_Loss: 0.1290, G_Loss: 0.6776, net1_Loss: 0.0274, net2_Loss: 0.1953, \n",
            "Step [52600/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0343, net2_Loss: 0.6314, \n",
            "Step [52700/100000], recon_Loss: 0.1254, G_Loss: 0.6753, net1_Loss: 0.0009, net2_Loss: 1.5080, \n",
            "Step [52800/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3860, \n",
            "Step [52900/100000], recon_Loss: 0.1309, G_Loss: 0.6790, net1_Loss: 0.0313, net2_Loss: 0.4838, \n",
            "Step [53000/100000], recon_Loss: 0.1213, G_Loss: 0.6931, net1_Loss: 0.1511, net2_Loss: 0.1342, \n",
            "Step [53100/100000], recon_Loss: 0.1312, G_Loss: 0.6553, net1_Loss: 0.0496, net2_Loss: 1.2619, \n",
            "Step [53200/100000], recon_Loss: 0.1253, G_Loss: 0.6771, net1_Loss: 0.3474, net2_Loss: 0.2021, \n",
            "Step [53300/100000], recon_Loss: 0.1264, G_Loss: 0.6331, net1_Loss: 0.0845, net2_Loss: 0.1593, \n",
            "Step [53400/100000], recon_Loss: 0.1254, G_Loss: 0.6723, net1_Loss: 0.0561, net2_Loss: 3.3231, \n",
            "Step [53500/100000], recon_Loss: 0.1298, G_Loss: 0.6765, net1_Loss: 0.0102, net2_Loss: 0.3556, \n",
            "Step [53600/100000], recon_Loss: 0.1252, G_Loss: 0.6732, net1_Loss: 0.0318, net2_Loss: 0.3518, \n",
            "Step [53700/100000], recon_Loss: 0.1186, G_Loss: 0.6465, net1_Loss: 0.0808, net2_Loss: 0.2818, \n",
            "Step [53800/100000], recon_Loss: 0.1319, G_Loss: 0.6732, net1_Loss: 0.0076, net2_Loss: 0.0944, \n",
            "Step [53900/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0078, net2_Loss: 0.4309, \n",
            "Step [54000/100000], recon_Loss: 0.1250, G_Loss: 0.6409, net1_Loss: 0.0232, net2_Loss: 0.5626, \n",
            "Step [54100/100000], recon_Loss: 0.1296, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5261, \n",
            "Step [54200/100000], recon_Loss: 0.1224, G_Loss: 0.6899, net1_Loss: 0.0071, net2_Loss: 0.3213, \n",
            "Step [54300/100000], recon_Loss: 0.1282, G_Loss: 0.6536, net1_Loss: 0.1641, net2_Loss: 0.0685, \n",
            "Step [54400/100000], recon_Loss: 0.1245, G_Loss: 0.6747, net1_Loss: 0.1031, net2_Loss: 0.1467, \n",
            "Step [54500/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0532, \n",
            "Step [54600/100000], recon_Loss: 0.1177, G_Loss: 0.5588, net1_Loss: 0.0511, net2_Loss: 0.0283, \n",
            "Step [54700/100000], recon_Loss: 0.1259, G_Loss: 0.6622, net1_Loss: 0.0188, net2_Loss: 0.0298, \n",
            "Step [54800/100000], recon_Loss: 0.1292, G_Loss: 0.6760, net1_Loss: 0.8337, net2_Loss: 1.0914, \n",
            "Step [54900/100000], recon_Loss: 0.1306, G_Loss: 0.7124, net1_Loss: 0.1251, net2_Loss: 0.5295, \n",
            "Step [55000/100000], recon_Loss: 0.1254, G_Loss: 0.6875, net1_Loss: 0.0118, net2_Loss: 1.1029, \n",
            "Step [55100/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.7740, \n",
            "Step [55200/100000], recon_Loss: 0.1308, G_Loss: 0.6749, net1_Loss: 0.0707, net2_Loss: 1.0477, \n",
            "Step [55300/100000], recon_Loss: 0.1211, G_Loss: 0.6931, net1_Loss: 0.0539, net2_Loss: 0.1835, \n",
            "Step [55400/100000], recon_Loss: 0.1310, G_Loss: 0.6544, net1_Loss: 0.0274, net2_Loss: 0.5037, \n",
            "Step [55500/100000], recon_Loss: 0.1252, G_Loss: 0.6762, net1_Loss: 0.0361, net2_Loss: 0.2773, \n",
            "Step [55600/100000], recon_Loss: 0.1263, G_Loss: 0.6216, net1_Loss: 0.0126, net2_Loss: 0.0567, \n",
            "Step [55700/100000], recon_Loss: 0.1253, G_Loss: 0.6794, net1_Loss: 0.0442, net2_Loss: 0.5697, \n",
            "Step [55800/100000], recon_Loss: 0.1298, G_Loss: 0.6728, net1_Loss: 0.0189, net2_Loss: 0.0544, \n",
            "Step [55900/100000], recon_Loss: 0.1253, G_Loss: 0.6752, net1_Loss: 0.0049, net2_Loss: 0.5520, \n",
            "Step [56000/100000], recon_Loss: 0.1187, G_Loss: 0.6382, net1_Loss: 0.0381, net2_Loss: 0.0997, \n",
            "Step [56100/100000], recon_Loss: 0.1320, G_Loss: 0.6728, net1_Loss: 0.0039, net2_Loss: 0.1425, \n",
            "Step [56200/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0004, net2_Loss: 0.2228, \n",
            "Step [56300/100000], recon_Loss: 0.1246, G_Loss: 0.6406, net1_Loss: 0.0235, net2_Loss: 0.4716, \n",
            "Step [56400/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3561, \n",
            "Step [56500/100000], recon_Loss: 0.1225, G_Loss: 0.6802, net1_Loss: 0.0473, net2_Loss: 0.2105, \n",
            "Step [56600/100000], recon_Loss: 0.1283, G_Loss: 0.6531, net1_Loss: 0.1329, net2_Loss: 1.1547, \n",
            "Step [56700/100000], recon_Loss: 0.1246, G_Loss: 0.6730, net1_Loss: 0.0730, net2_Loss: 0.5294, \n",
            "Step [56800/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3655, \n",
            "Step [56900/100000], recon_Loss: 0.1177, G_Loss: 0.5515, net1_Loss: 0.0126, net2_Loss: 0.3281, \n",
            "Step [57000/100000], recon_Loss: 0.1259, G_Loss: 0.6603, net1_Loss: 0.0070, net2_Loss: 0.6061, \n",
            "Step [57100/100000], recon_Loss: 0.1290, G_Loss: 0.6682, net1_Loss: 0.0569, net2_Loss: 0.3055, \n",
            "Step [57200/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0238, net2_Loss: 0.1120, \n",
            "Step [57300/100000], recon_Loss: 0.1253, G_Loss: 0.6750, net1_Loss: 0.0258, net2_Loss: 0.4199, \n",
            "Step [57400/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4918, \n",
            "Step [57500/100000], recon_Loss: 0.1309, G_Loss: 0.6743, net1_Loss: 0.0896, net2_Loss: 0.6813, \n",
            "Step [57600/100000], recon_Loss: 0.1214, G_Loss: 0.6931, net1_Loss: 0.0343, net2_Loss: 0.1987, \n",
            "Step [57700/100000], recon_Loss: 0.1311, G_Loss: 0.6636, net1_Loss: 0.0484, net2_Loss: 0.2054, \n",
            "Step [57800/100000], recon_Loss: 0.1252, G_Loss: 0.6786, net1_Loss: 0.4271, net2_Loss: 0.1800, \n",
            "Step [57900/100000], recon_Loss: 0.1264, G_Loss: 0.6161, net1_Loss: 0.0706, net2_Loss: 0.1472, \n",
            "Step [58000/100000], recon_Loss: 0.1253, G_Loss: 0.6721, net1_Loss: 0.0183, net2_Loss: 0.1085, \n",
            "Step [58100/100000], recon_Loss: 0.1298, G_Loss: 0.6719, net1_Loss: 0.0118, net2_Loss: 0.0389, \n",
            "Step [58200/100000], recon_Loss: 0.1253, G_Loss: 0.6732, net1_Loss: 0.1009, net2_Loss: 0.1815, \n",
            "Step [58300/100000], recon_Loss: 0.1188, G_Loss: 0.6411, net1_Loss: 0.1598, net2_Loss: 0.5046, \n",
            "Step [58400/100000], recon_Loss: 0.1320, G_Loss: 0.6753, net1_Loss: 0.0208, net2_Loss: 0.4456, \n",
            "Step [58500/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0134, net2_Loss: 2.0902, \n",
            "Step [58600/100000], recon_Loss: 0.1246, G_Loss: 0.6376, net1_Loss: 0.0899, net2_Loss: 2.6322, \n",
            "Step [58700/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.6088, \n",
            "Step [58800/100000], recon_Loss: 0.1225, G_Loss: 0.6752, net1_Loss: 0.0083, net2_Loss: 1.5403, \n",
            "Step [58900/100000], recon_Loss: 0.1282, G_Loss: 0.6548, net1_Loss: 0.3719, net2_Loss: 1.0584, \n",
            "Step [59000/100000], recon_Loss: 0.1246, G_Loss: 0.6727, net1_Loss: 0.0859, net2_Loss: 0.9609, \n",
            "Step [59100/100000], recon_Loss: 0.1250, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1955, \n",
            "Step [59200/100000], recon_Loss: 0.1176, G_Loss: 0.5570, net1_Loss: 0.0609, net2_Loss: 0.0445, \n",
            "Step [59300/100000], recon_Loss: 0.1259, G_Loss: 0.6668, net1_Loss: 0.0072, net2_Loss: 0.0741, \n",
            "Step [59400/100000], recon_Loss: 0.1290, G_Loss: 0.6766, net1_Loss: 0.0218, net2_Loss: 0.1349, \n",
            "Step [59500/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0051, net2_Loss: 0.0716, \n",
            "Step [59600/100000], recon_Loss: 0.1254, G_Loss: 0.6760, net1_Loss: 0.0011, net2_Loss: 0.1113, \n",
            "Step [59700/100000], recon_Loss: 0.1277, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0953, \n",
            "Step [59800/100000], recon_Loss: 0.1308, G_Loss: 0.6777, net1_Loss: 0.0089, net2_Loss: 0.0626, \n",
            "Step [59900/100000], recon_Loss: 0.1212, G_Loss: 0.6931, net1_Loss: 0.0827, net2_Loss: 0.2537, \n",
            "Step [60000/100000], recon_Loss: 0.1312, G_Loss: 0.6536, net1_Loss: 0.0434, net2_Loss: 0.1231, \n",
            "Step [60100/100000], recon_Loss: 0.1252, G_Loss: 0.6724, net1_Loss: 0.0414, net2_Loss: 0.0803, \n",
            "Step [60200/100000], recon_Loss: 0.1264, G_Loss: 0.6156, net1_Loss: 0.0963, net2_Loss: 0.0347, \n",
            "Step [60300/100000], recon_Loss: 0.1254, G_Loss: 0.6720, net1_Loss: 0.0207, net2_Loss: 0.1293, \n",
            "Step [60400/100000], recon_Loss: 0.1298, G_Loss: 0.6724, net1_Loss: 0.1585, net2_Loss: 0.0891, \n",
            "Step [60500/100000], recon_Loss: 0.1254, G_Loss: 0.6729, net1_Loss: 0.1954, net2_Loss: 0.9269, \n",
            "Step [60600/100000], recon_Loss: 0.1187, G_Loss: 0.6340, net1_Loss: 0.9244, net2_Loss: 2.5650, \n",
            "Step [60700/100000], recon_Loss: 0.1319, G_Loss: 0.6736, net1_Loss: 0.0098, net2_Loss: 0.4896, \n",
            "Step [60800/100000], recon_Loss: 0.1250, G_Loss: 0.6931, net1_Loss: 0.0403, net2_Loss: 0.4406, \n",
            "Step [60900/100000], recon_Loss: 0.1247, G_Loss: 0.6286, net1_Loss: 0.1359, net2_Loss: 0.5475, \n",
            "Step [61000/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4355, \n",
            "Step [61100/100000], recon_Loss: 0.1223, G_Loss: 0.6764, net1_Loss: 0.0226, net2_Loss: 0.0929, \n",
            "Step [61200/100000], recon_Loss: 0.1283, G_Loss: 0.6493, net1_Loss: 0.0510, net2_Loss: 0.1660, \n",
            "Step [61300/100000], recon_Loss: 0.1246, G_Loss: 0.6735, net1_Loss: 0.2933, net2_Loss: 0.1279, \n",
            "Step [61400/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1851, \n",
            "Step [61500/100000], recon_Loss: 0.1177, G_Loss: 0.5495, net1_Loss: 0.1933, net2_Loss: 0.2956, \n",
            "Step [61600/100000], recon_Loss: 0.1260, G_Loss: 0.6632, net1_Loss: 0.1554, net2_Loss: 1.5444, \n",
            "Step [61700/100000], recon_Loss: 0.1290, G_Loss: 0.6718, net1_Loss: 0.0961, net2_Loss: 0.1550, \n",
            "Step [61800/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0126, net2_Loss: 0.0858, \n",
            "Step [61900/100000], recon_Loss: 0.1253, G_Loss: 0.6744, net1_Loss: 0.0011, net2_Loss: 0.2519, \n",
            "Step [62000/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0914, \n",
            "Step [62100/100000], recon_Loss: 0.1307, G_Loss: 0.6764, net1_Loss: 0.0202, net2_Loss: 0.3503, \n",
            "Step [62200/100000], recon_Loss: 0.1211, G_Loss: 0.6931, net1_Loss: 0.0413, net2_Loss: 0.2073, \n",
            "Step [62300/100000], recon_Loss: 0.1311, G_Loss: 0.6520, net1_Loss: 0.0282, net2_Loss: 0.2035, \n",
            "Step [62400/100000], recon_Loss: 0.1251, G_Loss: 0.6647, net1_Loss: 0.1982, net2_Loss: 0.3522, \n",
            "Step [62500/100000], recon_Loss: 0.1264, G_Loss: 0.6184, net1_Loss: 0.1434, net2_Loss: 0.8079, \n",
            "Step [62600/100000], recon_Loss: 0.1255, G_Loss: 0.6731, net1_Loss: 0.3007, net2_Loss: 1.8940, \n",
            "Step [62700/100000], recon_Loss: 0.1299, G_Loss: 0.6734, net1_Loss: 0.0328, net2_Loss: 0.3393, \n",
            "Step [62800/100000], recon_Loss: 0.1253, G_Loss: 0.6728, net1_Loss: 0.0431, net2_Loss: 0.1628, \n",
            "Step [62900/100000], recon_Loss: 0.1188, G_Loss: 0.6347, net1_Loss: 0.1586, net2_Loss: 0.0587, \n",
            "Step [63000/100000], recon_Loss: 0.1320, G_Loss: 0.6741, net1_Loss: 0.0235, net2_Loss: 0.2660, \n",
            "Step [63100/100000], recon_Loss: 0.1249, G_Loss: 0.6969, net1_Loss: 0.0272, net2_Loss: 1.0060, \n",
            "Step [63200/100000], recon_Loss: 0.1246, G_Loss: 0.6414, net1_Loss: 0.2235, net2_Loss: 0.8793, \n",
            "Step [63300/100000], recon_Loss: 0.1295, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.8890, \n",
            "Step [63400/100000], recon_Loss: 0.1223, G_Loss: 0.6751, net1_Loss: 0.0062, net2_Loss: 0.1006, \n",
            "Step [63500/100000], recon_Loss: 0.1282, G_Loss: 0.6445, net1_Loss: 0.0385, net2_Loss: 0.0920, \n",
            "Step [63600/100000], recon_Loss: 0.1246, G_Loss: 0.6736, net1_Loss: 0.0335, net2_Loss: 0.3034, \n",
            "Step [63700/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5603, \n",
            "Step [63800/100000], recon_Loss: 0.1177, G_Loss: 0.5415, net1_Loss: 0.1155, net2_Loss: 0.0202, \n",
            "Step [63900/100000], recon_Loss: 0.1262, G_Loss: 0.6607, net1_Loss: 0.1089, net2_Loss: 0.3201, \n",
            "Step [64000/100000], recon_Loss: 0.1292, G_Loss: 0.6727, net1_Loss: 0.1152, net2_Loss: 0.1525, \n",
            "Step [64100/100000], recon_Loss: 0.1307, G_Loss: 0.6931, net1_Loss: 0.0137, net2_Loss: 0.7372, \n",
            "Step [64200/100000], recon_Loss: 0.1255, G_Loss: 0.6852, net1_Loss: 0.0011, net2_Loss: 0.1576, \n",
            "Step [64300/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3129, \n",
            "Step [64400/100000], recon_Loss: 0.1308, G_Loss: 0.6744, net1_Loss: 0.0458, net2_Loss: 1.0847, \n",
            "Step [64500/100000], recon_Loss: 0.1212, G_Loss: 0.6994, net1_Loss: 0.2648, net2_Loss: 0.2552, \n",
            "Step [64600/100000], recon_Loss: 0.1310, G_Loss: 0.6522, net1_Loss: 0.0578, net2_Loss: 0.1650, \n",
            "Step [64700/100000], recon_Loss: 0.1252, G_Loss: 0.6832, net1_Loss: 0.0413, net2_Loss: 0.0618, \n",
            "Step [64800/100000], recon_Loss: 0.1265, G_Loss: 0.6236, net1_Loss: 0.0735, net2_Loss: 0.2640, \n",
            "Step [64900/100000], recon_Loss: 0.1256, G_Loss: 0.6719, net1_Loss: 0.3976, net2_Loss: 0.8435, \n",
            "Step [65000/100000], recon_Loss: 0.1299, G_Loss: 0.6731, net1_Loss: 0.0633, net2_Loss: 0.1499, \n",
            "Step [65100/100000], recon_Loss: 0.1255, G_Loss: 0.6733, net1_Loss: 0.0571, net2_Loss: 0.5496, \n",
            "Step [65200/100000], recon_Loss: 0.1189, G_Loss: 0.6367, net1_Loss: 0.2752, net2_Loss: 0.5438, \n",
            "Step [65300/100000], recon_Loss: 0.1320, G_Loss: 0.6731, net1_Loss: 0.0113, net2_Loss: 0.5902, \n",
            "Step [65400/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0350, net2_Loss: 0.2772, \n",
            "Step [65500/100000], recon_Loss: 0.1246, G_Loss: 0.6381, net1_Loss: 0.0228, net2_Loss: 0.1161, \n",
            "Step [65600/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1235, \n",
            "Step [65700/100000], recon_Loss: 0.1223, G_Loss: 0.6757, net1_Loss: 0.0036, net2_Loss: 0.3343, \n",
            "Step [65800/100000], recon_Loss: 0.1283, G_Loss: 0.6430, net1_Loss: 0.0342, net2_Loss: 1.1130, \n",
            "Step [65900/100000], recon_Loss: 0.1248, G_Loss: 0.6721, net1_Loss: 0.3676, net2_Loss: 2.3764, \n",
            "Step [66000/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3807, \n",
            "Step [66100/100000], recon_Loss: 0.1178, G_Loss: 0.5434, net1_Loss: 0.3868, net2_Loss: 0.3424, \n",
            "Step [66200/100000], recon_Loss: 0.1259, G_Loss: 0.6540, net1_Loss: 0.3907, net2_Loss: 0.4336, \n",
            "Step [66300/100000], recon_Loss: 0.1290, G_Loss: 0.6673, net1_Loss: 0.0258, net2_Loss: 0.1310, \n",
            "Step [66400/100000], recon_Loss: 0.1304, G_Loss: 0.6931, net1_Loss: 0.0082, net2_Loss: 0.1918, \n",
            "Step [66500/100000], recon_Loss: 0.1254, G_Loss: 0.6743, net1_Loss: 0.0027, net2_Loss: 0.3393, \n",
            "Step [66600/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2073, \n",
            "Step [66700/100000], recon_Loss: 0.1309, G_Loss: 0.6735, net1_Loss: 0.0069, net2_Loss: 0.6705, \n",
            "Step [66800/100000], recon_Loss: 0.1212, G_Loss: 0.6953, net1_Loss: 0.2926, net2_Loss: 0.0925, \n",
            "Step [66900/100000], recon_Loss: 0.1311, G_Loss: 0.6542, net1_Loss: 0.0559, net2_Loss: 1.0921, \n",
            "Step [67000/100000], recon_Loss: 0.1252, G_Loss: 0.6656, net1_Loss: 0.1351, net2_Loss: 1.4011, \n",
            "Step [67100/100000], recon_Loss: 0.1264, G_Loss: 0.6156, net1_Loss: 0.2592, net2_Loss: 0.5425, \n",
            "Step [67200/100000], recon_Loss: 0.1255, G_Loss: 0.6698, net1_Loss: 0.1981, net2_Loss: 1.9232, \n",
            "Step [67300/100000], recon_Loss: 0.1298, G_Loss: 0.6787, net1_Loss: 0.0517, net2_Loss: 0.1541, \n",
            "Step [67400/100000], recon_Loss: 0.1253, G_Loss: 0.6726, net1_Loss: 0.0189, net2_Loss: 0.0636, \n",
            "Step [67500/100000], recon_Loss: 0.1186, G_Loss: 0.6378, net1_Loss: 0.0878, net2_Loss: 0.1120, \n",
            "Step [67600/100000], recon_Loss: 0.1320, G_Loss: 0.6734, net1_Loss: 0.0201, net2_Loss: 0.4143, \n",
            "Step [67700/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0499, net2_Loss: 0.5270, \n",
            "Step [67800/100000], recon_Loss: 0.1247, G_Loss: 0.6309, net1_Loss: 0.3701, net2_Loss: 1.5892, \n",
            "Step [67900/100000], recon_Loss: 0.1296, G_Loss: 0.7018, net1_Loss: 0.0000, net2_Loss: 2.7782, \n",
            "Step [68000/100000], recon_Loss: 0.1223, G_Loss: 0.6761, net1_Loss: 0.0007, net2_Loss: 0.6213, \n",
            "Step [68100/100000], recon_Loss: 0.1282, G_Loss: 0.6489, net1_Loss: 0.0625, net2_Loss: 0.1152, \n",
            "Step [68200/100000], recon_Loss: 0.1245, G_Loss: 0.6725, net1_Loss: 0.0279, net2_Loss: 0.0988, \n",
            "Step [68300/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1182, \n",
            "Step [68400/100000], recon_Loss: 0.1177, G_Loss: 0.5347, net1_Loss: 0.0263, net2_Loss: 0.0222, \n",
            "Step [68500/100000], recon_Loss: 0.1259, G_Loss: 0.6583, net1_Loss: 0.0175, net2_Loss: 0.1220, \n",
            "Step [68600/100000], recon_Loss: 0.1290, G_Loss: 0.6609, net1_Loss: 0.0109, net2_Loss: 0.1838, \n",
            "Step [68700/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0061, net2_Loss: 0.3274, \n",
            "Step [68800/100000], recon_Loss: 0.1254, G_Loss: 0.6746, net1_Loss: 0.0003, net2_Loss: 0.6795, \n",
            "Step [68900/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2171, \n",
            "Step [69000/100000], recon_Loss: 0.1308, G_Loss: 0.6729, net1_Loss: 0.0209, net2_Loss: 0.3234, \n",
            "Step [69100/100000], recon_Loss: 0.1211, G_Loss: 0.6993, net1_Loss: 0.0293, net2_Loss: 0.2941, \n",
            "Step [69200/100000], recon_Loss: 0.1310, G_Loss: 0.6528, net1_Loss: 0.0091, net2_Loss: 0.4059, \n",
            "Step [69300/100000], recon_Loss: 0.1251, G_Loss: 0.6576, net1_Loss: 0.0416, net2_Loss: 0.1659, \n",
            "Step [69400/100000], recon_Loss: 0.1264, G_Loss: 0.6151, net1_Loss: 0.0657, net2_Loss: 0.1207, \n",
            "Step [69500/100000], recon_Loss: 0.1254, G_Loss: 0.6659, net1_Loss: 0.0318, net2_Loss: 0.5670, \n",
            "Step [69600/100000], recon_Loss: 0.1298, G_Loss: 0.6726, net1_Loss: 0.0390, net2_Loss: 0.2868, \n",
            "Step [69700/100000], recon_Loss: 0.1253, G_Loss: 0.6744, net1_Loss: 0.0762, net2_Loss: 0.3306, \n",
            "Step [69800/100000], recon_Loss: 0.1185, G_Loss: 0.6377, net1_Loss: 0.2093, net2_Loss: 0.5169, \n",
            "Step [69900/100000], recon_Loss: 0.1319, G_Loss: 0.6724, net1_Loss: 0.0119, net2_Loss: 0.2097, \n",
            "Step [70000/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0690, net2_Loss: 0.2296, \n",
            "Step [70100/100000], recon_Loss: 0.1248, G_Loss: 0.6251, net1_Loss: 0.0946, net2_Loss: 0.4229, \n",
            "Step [70200/100000], recon_Loss: 0.1296, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4076, \n",
            "Step [70300/100000], recon_Loss: 0.1223, G_Loss: 0.6744, net1_Loss: 0.0124, net2_Loss: 0.4421, \n",
            "Step [70400/100000], recon_Loss: 0.1282, G_Loss: 0.6277, net1_Loss: 0.0741, net2_Loss: 0.3321, \n",
            "Step [70500/100000], recon_Loss: 0.1245, G_Loss: 0.6732, net1_Loss: 0.0387, net2_Loss: 0.2347, \n",
            "Step [70600/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0627, \n",
            "Step [70700/100000], recon_Loss: 0.1179, G_Loss: 0.5378, net1_Loss: 0.5362, net2_Loss: 0.2338, \n",
            "Step [70800/100000], recon_Loss: 0.1260, G_Loss: 0.6548, net1_Loss: 0.0321, net2_Loss: 0.9638, \n",
            "Step [70900/100000], recon_Loss: 0.1290, G_Loss: 0.6564, net1_Loss: 0.0312, net2_Loss: 0.6558, \n",
            "Step [71000/100000], recon_Loss: 0.1304, G_Loss: 0.7065, net1_Loss: 0.0186, net2_Loss: 0.0887, \n",
            "Step [71100/100000], recon_Loss: 0.1254, G_Loss: 0.6741, net1_Loss: 0.0000, net2_Loss: 0.1984, \n",
            "Step [71200/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2414, \n",
            "Step [71300/100000], recon_Loss: 0.1308, G_Loss: 0.6739, net1_Loss: 0.0601, net2_Loss: 0.7796, \n",
            "Step [71400/100000], recon_Loss: 0.1212, G_Loss: 0.6931, net1_Loss: 0.0470, net2_Loss: 0.0907, \n",
            "Step [71500/100000], recon_Loss: 0.1312, G_Loss: 0.6543, net1_Loss: 0.0986, net2_Loss: 0.2739, \n",
            "Step [71600/100000], recon_Loss: 0.1255, G_Loss: 0.6628, net1_Loss: 0.4987, net2_Loss: 0.1196, \n",
            "Step [71700/100000], recon_Loss: 0.1264, G_Loss: 0.6141, net1_Loss: 0.0489, net2_Loss: 0.1372, \n",
            "Step [71800/100000], recon_Loss: 0.1262, G_Loss: 0.6721, net1_Loss: 0.1063, net2_Loss: 0.5307, \n",
            "Step [71900/100000], recon_Loss: 0.1299, G_Loss: 0.6707, net1_Loss: 0.1133, net2_Loss: 1.5707, \n",
            "Step [72000/100000], recon_Loss: 0.1252, G_Loss: 0.6719, net1_Loss: 0.0489, net2_Loss: 0.3078, \n",
            "Step [72100/100000], recon_Loss: 0.1185, G_Loss: 0.6429, net1_Loss: 0.0996, net2_Loss: 0.2100, \n",
            "Step [72200/100000], recon_Loss: 0.1319, G_Loss: 0.6739, net1_Loss: 0.0042, net2_Loss: 0.0615, \n",
            "Step [72300/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0081, net2_Loss: 0.0912, \n",
            "Step [72400/100000], recon_Loss: 0.1247, G_Loss: 0.6194, net1_Loss: 0.0262, net2_Loss: 0.0658, \n",
            "Step [72500/100000], recon_Loss: 0.1292, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1545, \n",
            "Step [72600/100000], recon_Loss: 0.1222, G_Loss: 0.6733, net1_Loss: 0.0019, net2_Loss: 0.0605, \n",
            "Step [72700/100000], recon_Loss: 0.1283, G_Loss: 0.6211, net1_Loss: 0.0326, net2_Loss: 0.0471, \n",
            "Step [72800/100000], recon_Loss: 0.1248, G_Loss: 0.6749, net1_Loss: 0.6533, net2_Loss: 0.7650, \n",
            "Step [72900/100000], recon_Loss: 0.1246, G_Loss: 0.6947, net1_Loss: 0.0000, net2_Loss: 0.7186, \n",
            "Step [73000/100000], recon_Loss: 0.1177, G_Loss: 0.5314, net1_Loss: 0.0800, net2_Loss: 0.4407, \n",
            "Step [73100/100000], recon_Loss: 0.1259, G_Loss: 0.6552, net1_Loss: 0.0542, net2_Loss: 0.5101, \n",
            "Step [73200/100000], recon_Loss: 0.1290, G_Loss: 0.6550, net1_Loss: 0.0176, net2_Loss: 0.2182, \n",
            "Step [73300/100000], recon_Loss: 0.1305, G_Loss: 0.6931, net1_Loss: 0.0260, net2_Loss: 0.0736, \n",
            "Step [73400/100000], recon_Loss: 0.1253, G_Loss: 0.6745, net1_Loss: 0.0182, net2_Loss: 0.0469, \n",
            "Step [73500/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0503, \n",
            "Step [73600/100000], recon_Loss: 0.1308, G_Loss: 0.6727, net1_Loss: 0.0525, net2_Loss: 0.1608, \n",
            "Step [73700/100000], recon_Loss: 0.1213, G_Loss: 0.6931, net1_Loss: 0.5477, net2_Loss: 1.0057, \n",
            "Step [73800/100000], recon_Loss: 0.1310, G_Loss: 0.6564, net1_Loss: 0.0089, net2_Loss: 0.5196, \n",
            "Step [73900/100000], recon_Loss: 0.1251, G_Loss: 0.6666, net1_Loss: 0.1403, net2_Loss: 0.2004, \n",
            "Step [74000/100000], recon_Loss: 0.1264, G_Loss: 0.6132, net1_Loss: 0.0967, net2_Loss: 0.0877, \n",
            "Step [74100/100000], recon_Loss: 0.1253, G_Loss: 0.6632, net1_Loss: 0.0052, net2_Loss: 0.4296, \n",
            "Step [74200/100000], recon_Loss: 0.1298, G_Loss: 0.6722, net1_Loss: 0.0267, net2_Loss: 0.3369, \n",
            "Step [74300/100000], recon_Loss: 0.1252, G_Loss: 0.6720, net1_Loss: 0.0378, net2_Loss: 0.1842, \n",
            "Step [74400/100000], recon_Loss: 0.1185, G_Loss: 0.6349, net1_Loss: 0.1212, net2_Loss: 0.9751, \n",
            "Step [74500/100000], recon_Loss: 0.1321, G_Loss: 0.6724, net1_Loss: 0.0131, net2_Loss: 1.5358, \n",
            "Step [74600/100000], recon_Loss: 0.1250, G_Loss: 0.6936, net1_Loss: 0.0387, net2_Loss: 0.3787, \n",
            "Step [74700/100000], recon_Loss: 0.1248, G_Loss: 0.6229, net1_Loss: 0.2547, net2_Loss: 0.2182, \n",
            "Step [74800/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0828, \n",
            "Step [74900/100000], recon_Loss: 0.1223, G_Loss: 0.6728, net1_Loss: 0.0139, net2_Loss: 0.1132, \n",
            "Step [75000/100000], recon_Loss: 0.1282, G_Loss: 0.6241, net1_Loss: 0.0797, net2_Loss: 0.0526, \n",
            "Step [75100/100000], recon_Loss: 0.1245, G_Loss: 0.6765, net1_Loss: 0.0706, net2_Loss: 0.1663, \n",
            "Step [75200/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0484, \n",
            "Step [75300/100000], recon_Loss: 0.1177, G_Loss: 0.5418, net1_Loss: 0.0536, net2_Loss: 0.0342, \n",
            "Step [75400/100000], recon_Loss: 0.1260, G_Loss: 0.6545, net1_Loss: 0.2898, net2_Loss: 0.2472, \n",
            "Step [75500/100000], recon_Loss: 0.1290, G_Loss: 0.6603, net1_Loss: 0.0986, net2_Loss: 0.1862, \n",
            "Step [75600/100000], recon_Loss: 0.1306, G_Loss: 0.6931, net1_Loss: 0.0304, net2_Loss: 0.6928, \n",
            "Step [75700/100000], recon_Loss: 0.1254, G_Loss: 0.6766, net1_Loss: 0.0353, net2_Loss: 0.4460, \n",
            "Step [75800/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2715, \n",
            "Step [75900/100000], recon_Loss: 0.1307, G_Loss: 0.6727, net1_Loss: 0.0379, net2_Loss: 0.4960, \n",
            "Step [76000/100000], recon_Loss: 0.1211, G_Loss: 0.7072, net1_Loss: 0.1201, net2_Loss: 0.0650, \n",
            "Step [76100/100000], recon_Loss: 0.1311, G_Loss: 0.6543, net1_Loss: 0.0448, net2_Loss: 0.4796, \n",
            "Step [76200/100000], recon_Loss: 0.1253, G_Loss: 0.6546, net1_Loss: 0.1896, net2_Loss: 0.1265, \n",
            "Step [76300/100000], recon_Loss: 0.1264, G_Loss: 0.6175, net1_Loss: 0.1523, net2_Loss: 1.0841, \n",
            "Step [76400/100000], recon_Loss: 0.1253, G_Loss: 0.6702, net1_Loss: 0.3117, net2_Loss: 1.5004, \n",
            "Step [76500/100000], recon_Loss: 0.1298, G_Loss: 0.6751, net1_Loss: 0.3657, net2_Loss: 0.5926, \n",
            "Step [76600/100000], recon_Loss: 0.1252, G_Loss: 0.6722, net1_Loss: 0.0163, net2_Loss: 0.2013, \n",
            "Step [76700/100000], recon_Loss: 0.1185, G_Loss: 0.6321, net1_Loss: 0.0263, net2_Loss: 0.1839, \n",
            "Step [76800/100000], recon_Loss: 0.1319, G_Loss: 0.6730, net1_Loss: 0.0062, net2_Loss: 0.1889, \n",
            "Step [76900/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.1357, \n",
            "Step [77000/100000], recon_Loss: 0.1248, G_Loss: 0.6256, net1_Loss: 0.0596, net2_Loss: 0.2486, \n",
            "Step [77100/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.6813, \n",
            "Step [77200/100000], recon_Loss: 0.1222, G_Loss: 0.6657, net1_Loss: 0.0073, net2_Loss: 0.2631, \n",
            "Step [77300/100000], recon_Loss: 0.1282, G_Loss: 0.6241, net1_Loss: 0.0158, net2_Loss: 0.0989, \n",
            "Step [77400/100000], recon_Loss: 0.1244, G_Loss: 0.6725, net1_Loss: 0.0465, net2_Loss: 0.2171, \n",
            "Step [77500/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4002, \n",
            "Step [77600/100000], recon_Loss: 0.1178, G_Loss: 0.5276, net1_Loss: 0.0321, net2_Loss: 0.1113, \n",
            "Step [77700/100000], recon_Loss: 0.1259, G_Loss: 0.6525, net1_Loss: 0.1034, net2_Loss: 0.3716, \n",
            "Step [77800/100000], recon_Loss: 0.1291, G_Loss: 0.6600, net1_Loss: 0.0169, net2_Loss: 0.0973, \n",
            "Step [77900/100000], recon_Loss: 0.1304, G_Loss: 0.6931, net1_Loss: 0.0244, net2_Loss: 0.2671, \n",
            "Step [78000/100000], recon_Loss: 0.1253, G_Loss: 0.6749, net1_Loss: 0.0099, net2_Loss: 0.9404, \n",
            "Step [78100/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2711, \n",
            "Step [78200/100000], recon_Loss: 0.1308, G_Loss: 0.6733, net1_Loss: 0.0193, net2_Loss: 0.0910, \n",
            "Step [78300/100000], recon_Loss: 0.1211, G_Loss: 0.6921, net1_Loss: 0.0118, net2_Loss: 0.1435, \n",
            "Step [78400/100000], recon_Loss: 0.1311, G_Loss: 0.6538, net1_Loss: 0.0396, net2_Loss: 2.0806, \n",
            "Step [78500/100000], recon_Loss: 0.1251, G_Loss: 0.6568, net1_Loss: 0.0732, net2_Loss: 0.3687, \n",
            "Step [78600/100000], recon_Loss: 0.1263, G_Loss: 0.6120, net1_Loss: 0.0745, net2_Loss: 0.2236, \n",
            "Step [78700/100000], recon_Loss: 0.1253, G_Loss: 0.6589, net1_Loss: 0.1423, net2_Loss: 0.1619, \n",
            "Step [78800/100000], recon_Loss: 0.1298, G_Loss: 0.6599, net1_Loss: 0.1511, net2_Loss: 0.2100, \n",
            "Step [78900/100000], recon_Loss: 0.1252, G_Loss: 0.6718, net1_Loss: 0.0440, net2_Loss: 0.1108, \n",
            "Step [79000/100000], recon_Loss: 0.1185, G_Loss: 0.6339, net1_Loss: 0.1076, net2_Loss: 0.3622, \n",
            "Step [79100/100000], recon_Loss: 0.1319, G_Loss: 0.6727, net1_Loss: 0.0272, net2_Loss: 0.1147, \n",
            "Step [79200/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0447, net2_Loss: 0.6716, \n",
            "Step [79300/100000], recon_Loss: 0.1247, G_Loss: 0.6241, net1_Loss: 0.0371, net2_Loss: 0.3934, \n",
            "Step [79400/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.6357, \n",
            "Step [79500/100000], recon_Loss: 0.1224, G_Loss: 0.6584, net1_Loss: 0.0297, net2_Loss: 0.5270, \n",
            "Step [79600/100000], recon_Loss: 0.1283, G_Loss: 0.6153, net1_Loss: 0.0298, net2_Loss: 0.2230, \n",
            "Step [79700/100000], recon_Loss: 0.1247, G_Loss: 0.6825, net1_Loss: 0.2792, net2_Loss: 0.1982, \n",
            "Step [79800/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.4250, \n",
            "Step [79900/100000], recon_Loss: 0.1177, G_Loss: 0.5149, net1_Loss: 0.0498, net2_Loss: 0.0739, \n",
            "Step [80000/100000], recon_Loss: 0.1259, G_Loss: 0.6520, net1_Loss: 0.0655, net2_Loss: 0.0441, \n",
            "Step [80100/100000], recon_Loss: 0.1290, G_Loss: 0.6554, net1_Loss: 0.0229, net2_Loss: 0.0440, \n",
            "Step [80200/100000], recon_Loss: 0.1304, G_Loss: 0.7034, net1_Loss: 0.0080, net2_Loss: 0.2646, \n",
            "Step [80300/100000], recon_Loss: 0.1255, G_Loss: 0.6744, net1_Loss: 0.0299, net2_Loss: 0.5676, \n",
            "Step [80400/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1701, \n",
            "Step [80500/100000], recon_Loss: 0.1310, G_Loss: 0.6733, net1_Loss: 0.1369, net2_Loss: 0.1519, \n",
            "Step [80600/100000], recon_Loss: 0.1211, G_Loss: 0.6906, net1_Loss: 0.1357, net2_Loss: 0.0475, \n",
            "Step [80700/100000], recon_Loss: 0.1309, G_Loss: 0.6518, net1_Loss: 0.0338, net2_Loss: 0.2683, \n",
            "Step [80800/100000], recon_Loss: 0.1251, G_Loss: 0.6592, net1_Loss: 0.0580, net2_Loss: 0.1131, \n",
            "Step [80900/100000], recon_Loss: 0.1263, G_Loss: 0.6084, net1_Loss: 0.0764, net2_Loss: 0.1011, \n",
            "Step [81000/100000], recon_Loss: 0.1253, G_Loss: 0.6607, net1_Loss: 0.0803, net2_Loss: 0.4321, \n",
            "Step [81100/100000], recon_Loss: 0.1298, G_Loss: 0.6566, net1_Loss: 0.1156, net2_Loss: 1.6998, \n",
            "Step [81200/100000], recon_Loss: 0.1253, G_Loss: 0.6739, net1_Loss: 0.1026, net2_Loss: 2.4430, \n",
            "Step [81300/100000], recon_Loss: 0.1187, G_Loss: 0.6346, net1_Loss: 0.1322, net2_Loss: 0.9753, \n",
            "Step [81400/100000], recon_Loss: 0.1320, G_Loss: 0.6719, net1_Loss: 0.0072, net2_Loss: 0.2422, \n",
            "Step [81500/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0249, net2_Loss: 0.0826, \n",
            "Step [81600/100000], recon_Loss: 0.1247, G_Loss: 0.6164, net1_Loss: 0.0746, net2_Loss: 0.1916, \n",
            "Step [81700/100000], recon_Loss: 0.1294, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 1.4884, \n",
            "Step [81800/100000], recon_Loss: 0.1224, G_Loss: 0.6574, net1_Loss: 0.1233, net2_Loss: 0.6126, \n",
            "Step [81900/100000], recon_Loss: 0.1282, G_Loss: 0.6217, net1_Loss: 0.1501, net2_Loss: 0.4572, \n",
            "Step [82000/100000], recon_Loss: 0.1245, G_Loss: 0.6750, net1_Loss: 0.0739, net2_Loss: 0.1913, \n",
            "Step [82100/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0923, \n",
            "Step [82200/100000], recon_Loss: 0.1176, G_Loss: 0.5193, net1_Loss: 0.0536, net2_Loss: 0.0290, \n",
            "Step [82300/100000], recon_Loss: 0.1258, G_Loss: 0.6535, net1_Loss: 0.0022, net2_Loss: 0.1516, \n",
            "Step [82400/100000], recon_Loss: 0.1289, G_Loss: 0.6581, net1_Loss: 0.0317, net2_Loss: 0.1239, \n",
            "Step [82500/100000], recon_Loss: 0.1304, G_Loss: 0.6860, net1_Loss: 0.0054, net2_Loss: 0.0507, \n",
            "Step [82600/100000], recon_Loss: 0.1253, G_Loss: 0.6749, net1_Loss: 0.0000, net2_Loss: 0.1011, \n",
            "Step [82700/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0579, \n",
            "Step [82800/100000], recon_Loss: 0.1308, G_Loss: 0.6723, net1_Loss: 0.0037, net2_Loss: 0.3264, \n",
            "Step [82900/100000], recon_Loss: 0.1211, G_Loss: 0.6931, net1_Loss: 0.0073, net2_Loss: 0.1127, \n",
            "Step [83000/100000], recon_Loss: 0.1310, G_Loss: 0.6513, net1_Loss: 0.0073, net2_Loss: 0.1261, \n",
            "Step [83100/100000], recon_Loss: 0.1250, G_Loss: 0.6358, net1_Loss: 0.0132, net2_Loss: 0.3596, \n",
            "Step [83200/100000], recon_Loss: 0.1263, G_Loss: 0.5960, net1_Loss: 0.0454, net2_Loss: 1.0035, \n",
            "Step [83300/100000], recon_Loss: 0.1254, G_Loss: 0.6559, net1_Loss: 0.0754, net2_Loss: 0.3425, \n",
            "Step [83400/100000], recon_Loss: 0.1298, G_Loss: 0.6516, net1_Loss: 0.2232, net2_Loss: 0.0530, \n",
            "Step [83500/100000], recon_Loss: 0.1254, G_Loss: 0.6721, net1_Loss: 0.1225, net2_Loss: 0.3902, \n",
            "Step [83600/100000], recon_Loss: 0.1187, G_Loss: 0.6206, net1_Loss: 0.6890, net2_Loss: 0.1458, \n",
            "Step [83700/100000], recon_Loss: 0.1319, G_Loss: 0.6677, net1_Loss: 0.0005, net2_Loss: 0.7508, \n",
            "Step [83800/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0287, net2_Loss: 0.3239, \n",
            "Step [83900/100000], recon_Loss: 0.1246, G_Loss: 0.6224, net1_Loss: 0.0262, net2_Loss: 0.0665, \n",
            "Step [84000/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3354, \n",
            "Step [84100/100000], recon_Loss: 0.1223, G_Loss: 0.6586, net1_Loss: 0.0061, net2_Loss: 0.1389, \n",
            "Step [84200/100000], recon_Loss: 0.1281, G_Loss: 0.6037, net1_Loss: 0.0215, net2_Loss: 0.3241, \n",
            "Step [84300/100000], recon_Loss: 0.1245, G_Loss: 0.6696, net1_Loss: 0.3045, net2_Loss: 1.0621, \n",
            "Step [84400/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.6347, \n",
            "Step [84500/100000], recon_Loss: 0.1177, G_Loss: 0.5146, net1_Loss: 0.1868, net2_Loss: 0.2884, \n",
            "Step [84600/100000], recon_Loss: 0.1259, G_Loss: 0.6520, net1_Loss: 0.0177, net2_Loss: 0.1036, \n",
            "Step [84700/100000], recon_Loss: 0.1290, G_Loss: 0.6557, net1_Loss: 0.0132, net2_Loss: 0.0704, \n",
            "Step [84800/100000], recon_Loss: 0.1304, G_Loss: 0.6931, net1_Loss: 0.0082, net2_Loss: 0.1544, \n",
            "Step [84900/100000], recon_Loss: 0.1254, G_Loss: 0.6735, net1_Loss: 0.0063, net2_Loss: 0.2655, \n",
            "Step [85000/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0775, \n",
            "Step [85100/100000], recon_Loss: 0.1309, G_Loss: 0.6722, net1_Loss: 0.0135, net2_Loss: 0.1746, \n",
            "Step [85200/100000], recon_Loss: 0.1211, G_Loss: 0.6862, net1_Loss: 0.0684, net2_Loss: 0.0934, \n",
            "Step [85300/100000], recon_Loss: 0.1310, G_Loss: 0.6628, net1_Loss: 0.0291, net2_Loss: 0.3252, \n",
            "Step [85400/100000], recon_Loss: 0.1252, G_Loss: 0.6447, net1_Loss: 0.0563, net2_Loss: 0.3253, \n",
            "Step [85500/100000], recon_Loss: 0.1264, G_Loss: 0.5918, net1_Loss: 0.0239, net2_Loss: 0.0887, \n",
            "Step [85600/100000], recon_Loss: 0.1253, G_Loss: 0.6539, net1_Loss: 0.0498, net2_Loss: 0.4041, \n",
            "Step [85700/100000], recon_Loss: 0.1298, G_Loss: 0.6550, net1_Loss: 0.1547, net2_Loss: 0.5469, \n",
            "Step [85800/100000], recon_Loss: 0.1254, G_Loss: 0.6734, net1_Loss: 0.0521, net2_Loss: 0.9787, \n",
            "Step [85900/100000], recon_Loss: 0.1186, G_Loss: 0.6072, net1_Loss: 0.4636, net2_Loss: 0.8115, \n",
            "Step [86000/100000], recon_Loss: 0.1320, G_Loss: 0.6712, net1_Loss: 0.0130, net2_Loss: 0.5254, \n",
            "Step [86100/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0097, net2_Loss: 0.2147, \n",
            "Step [86200/100000], recon_Loss: 0.1246, G_Loss: 0.6197, net1_Loss: 0.0241, net2_Loss: 0.0637, \n",
            "Step [86300/100000], recon_Loss: 0.1293, G_Loss: 0.6969, net1_Loss: 0.0000, net2_Loss: 0.3143, \n",
            "Step [86400/100000], recon_Loss: 0.1222, G_Loss: 0.6645, net1_Loss: 0.0675, net2_Loss: 0.1556, \n",
            "Step [86500/100000], recon_Loss: 0.1282, G_Loss: 0.6113, net1_Loss: 0.1453, net2_Loss: 0.1152, \n",
            "Step [86600/100000], recon_Loss: 0.1245, G_Loss: 0.6610, net1_Loss: 0.0259, net2_Loss: 0.0955, \n",
            "Step [86700/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1627, \n",
            "Step [86800/100000], recon_Loss: 0.1178, G_Loss: 0.5207, net1_Loss: 0.0616, net2_Loss: 0.1635, \n",
            "Step [86900/100000], recon_Loss: 0.1259, G_Loss: 0.6522, net1_Loss: 0.0212, net2_Loss: 0.2482, \n",
            "Step [87000/100000], recon_Loss: 0.1289, G_Loss: 0.6572, net1_Loss: 0.0112, net2_Loss: 0.2758, \n",
            "Step [87100/100000], recon_Loss: 0.1304, G_Loss: 0.6759, net1_Loss: 0.0181, net2_Loss: 0.2179, \n",
            "Step [87200/100000], recon_Loss: 0.1253, G_Loss: 0.6730, net1_Loss: 0.0155, net2_Loss: 0.4409, \n",
            "Step [87300/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3410, \n",
            "Step [87400/100000], recon_Loss: 0.1308, G_Loss: 0.6735, net1_Loss: 0.1341, net2_Loss: 0.5246, \n",
            "Step [87500/100000], recon_Loss: 0.1211, G_Loss: 0.6857, net1_Loss: 0.1128, net2_Loss: 0.1025, \n",
            "Step [87600/100000], recon_Loss: 0.1311, G_Loss: 0.6513, net1_Loss: 0.0479, net2_Loss: 0.3741, \n",
            "Step [87700/100000], recon_Loss: 0.1252, G_Loss: 0.6470, net1_Loss: 0.0274, net2_Loss: 0.3130, \n",
            "Step [87800/100000], recon_Loss: 0.1264, G_Loss: 0.5930, net1_Loss: 0.3679, net2_Loss: 0.3733, \n",
            "Step [87900/100000], recon_Loss: 0.1254, G_Loss: 0.6569, net1_Loss: 0.5141, net2_Loss: 1.9833, \n",
            "Step [88000/100000], recon_Loss: 0.1298, G_Loss: 0.6562, net1_Loss: 0.0745, net2_Loss: 0.5560, \n",
            "Step [88100/100000], recon_Loss: 0.1252, G_Loss: 0.6731, net1_Loss: 0.0038, net2_Loss: 0.1593, \n",
            "Step [88200/100000], recon_Loss: 0.1185, G_Loss: 0.6103, net1_Loss: 0.0266, net2_Loss: 0.1378, \n",
            "Step [88300/100000], recon_Loss: 0.1319, G_Loss: 0.6657, net1_Loss: 0.0217, net2_Loss: 0.0937, \n",
            "Step [88400/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0005, net2_Loss: 0.0565, \n",
            "Step [88500/100000], recon_Loss: 0.1246, G_Loss: 0.6179, net1_Loss: 0.0042, net2_Loss: 0.0837, \n",
            "Step [88600/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1416, \n",
            "Step [88700/100000], recon_Loss: 0.1222, G_Loss: 0.6567, net1_Loss: 0.0040, net2_Loss: 0.0585, \n",
            "Step [88800/100000], recon_Loss: 0.1281, G_Loss: 0.6186, net1_Loss: 0.0095, net2_Loss: 0.2074, \n",
            "Step [88900/100000], recon_Loss: 0.1245, G_Loss: 0.6574, net1_Loss: 0.0191, net2_Loss: 0.2076, \n",
            "Step [89000/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.5583, \n",
            "Step [89100/100000], recon_Loss: 0.1177, G_Loss: 0.4850, net1_Loss: 0.0255, net2_Loss: 0.1774, \n",
            "Step [89200/100000], recon_Loss: 0.1259, G_Loss: 0.6520, net1_Loss: 0.0027, net2_Loss: 0.1077, \n",
            "Step [89300/100000], recon_Loss: 0.1290, G_Loss: 0.6548, net1_Loss: 0.0097, net2_Loss: 0.0697, \n",
            "Step [89400/100000], recon_Loss: 0.1305, G_Loss: 0.6750, net1_Loss: 0.0218, net2_Loss: 0.4069, \n",
            "Step [89500/100000], recon_Loss: 0.1253, G_Loss: 0.6751, net1_Loss: 0.0004, net2_Loss: 0.7589, \n",
            "Step [89600/100000], recon_Loss: 0.1274, G_Loss: 0.7069, net1_Loss: 0.0000, net2_Loss: 0.4739, \n",
            "Step [89700/100000], recon_Loss: 0.1308, G_Loss: 0.6727, net1_Loss: 0.0647, net2_Loss: 0.3064, \n",
            "Step [89800/100000], recon_Loss: 0.1211, G_Loss: 0.6745, net1_Loss: 0.3044, net2_Loss: 0.0521, \n",
            "Step [89900/100000], recon_Loss: 0.1310, G_Loss: 0.6560, net1_Loss: 0.0108, net2_Loss: 0.2095, \n",
            "Step [90000/100000], recon_Loss: 0.1251, G_Loss: 0.6384, net1_Loss: 0.0188, net2_Loss: 0.0455, \n",
            "Step [90100/100000], recon_Loss: 0.1263, G_Loss: 0.6003, net1_Loss: 0.0104, net2_Loss: 0.0276, \n",
            "Step [90200/100000], recon_Loss: 0.1253, G_Loss: 0.6571, net1_Loss: 0.0136, net2_Loss: 0.0908, \n",
            "Step [90300/100000], recon_Loss: 0.1297, G_Loss: 0.6550, net1_Loss: 0.0181, net2_Loss: 0.0411, \n",
            "Step [90400/100000], recon_Loss: 0.1252, G_Loss: 0.6729, net1_Loss: 0.0134, net2_Loss: 1.1831, \n",
            "Step [90500/100000], recon_Loss: 0.1185, G_Loss: 0.6034, net1_Loss: 0.1010, net2_Loss: 2.2312, \n",
            "Step [90600/100000], recon_Loss: 0.1318, G_Loss: 0.6579, net1_Loss: 0.0046, net2_Loss: 1.3101, \n",
            "Step [90700/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0260, net2_Loss: 0.1418, \n",
            "Step [90800/100000], recon_Loss: 0.1246, G_Loss: 0.6180, net1_Loss: 0.0496, net2_Loss: 0.0565, \n",
            "Step [90900/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1032, \n",
            "Step [91000/100000], recon_Loss: 0.1222, G_Loss: 0.6548, net1_Loss: 0.0009, net2_Loss: 0.1510, \n",
            "Step [91100/100000], recon_Loss: 0.1282, G_Loss: 0.5927, net1_Loss: 0.0683, net2_Loss: 0.0890, \n",
            "Step [91200/100000], recon_Loss: 0.1246, G_Loss: 0.6615, net1_Loss: 0.2010, net2_Loss: 0.1755, \n",
            "Step [91300/100000], recon_Loss: 0.1245, G_Loss: 0.6952, net1_Loss: 0.0000, net2_Loss: 0.0763, \n",
            "Step [91400/100000], recon_Loss: 0.1177, G_Loss: 0.4850, net1_Loss: 0.0788, net2_Loss: 0.0197, \n",
            "Step [91500/100000], recon_Loss: 0.1259, G_Loss: 0.6528, net1_Loss: 0.1445, net2_Loss: 0.0947, \n",
            "Step [91600/100000], recon_Loss: 0.1291, G_Loss: 0.6528, net1_Loss: 0.3520, net2_Loss: 0.1763, \n",
            "Step [91700/100000], recon_Loss: 0.1306, G_Loss: 0.6790, net1_Loss: 0.0150, net2_Loss: 0.2471, \n",
            "Step [91800/100000], recon_Loss: 0.1254, G_Loss: 0.6758, net1_Loss: 0.0045, net2_Loss: 0.2862, \n",
            "Step [91900/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.3057, \n",
            "Step [92000/100000], recon_Loss: 0.1307, G_Loss: 0.6729, net1_Loss: 0.0210, net2_Loss: 0.1643, \n",
            "Step [92100/100000], recon_Loss: 0.1211, G_Loss: 0.6866, net1_Loss: 0.0208, net2_Loss: 0.0615, \n",
            "Step [92200/100000], recon_Loss: 0.1310, G_Loss: 0.6517, net1_Loss: 0.0304, net2_Loss: 0.5585, \n",
            "Step [92300/100000], recon_Loss: 0.1251, G_Loss: 0.6545, net1_Loss: 0.0277, net2_Loss: 0.2945, \n",
            "Step [92400/100000], recon_Loss: 0.1263, G_Loss: 0.5922, net1_Loss: 0.1329, net2_Loss: 0.1947, \n",
            "Step [92500/100000], recon_Loss: 0.1255, G_Loss: 0.6521, net1_Loss: 0.1824, net2_Loss: 0.3123, \n",
            "Step [92600/100000], recon_Loss: 0.1298, G_Loss: 0.6535, net1_Loss: 0.0384, net2_Loss: 0.1251, \n",
            "Step [92700/100000], recon_Loss: 0.1252, G_Loss: 0.6719, net1_Loss: 0.0147, net2_Loss: 0.7645, \n",
            "Step [92800/100000], recon_Loss: 0.1186, G_Loss: 0.6031, net1_Loss: 0.0656, net2_Loss: 0.8942, \n",
            "Step [92900/100000], recon_Loss: 0.1319, G_Loss: 0.6587, net1_Loss: 0.0116, net2_Loss: 0.5620, \n",
            "Step [93000/100000], recon_Loss: 0.1249, G_Loss: 0.6931, net1_Loss: 0.0412, net2_Loss: 0.1644, \n",
            "Step [93100/100000], recon_Loss: 0.1247, G_Loss: 0.6364, net1_Loss: 0.0861, net2_Loss: 0.0677, \n",
            "Step [93200/100000], recon_Loss: 0.1293, G_Loss: 0.6994, net1_Loss: 0.0000, net2_Loss: 0.1196, \n",
            "Step [93300/100000], recon_Loss: 0.1223, G_Loss: 0.6583, net1_Loss: 0.0235, net2_Loss: 0.2055, \n",
            "Step [93400/100000], recon_Loss: 0.1283, G_Loss: 0.6006, net1_Loss: 0.1307, net2_Loss: 0.4400, \n",
            "Step [93500/100000], recon_Loss: 0.1245, G_Loss: 0.6598, net1_Loss: 0.0800, net2_Loss: 1.3984, \n",
            "Step [93600/100000], recon_Loss: 0.1245, G_Loss: 0.6948, net1_Loss: 0.0000, net2_Loss: 0.9036, \n",
            "Step [93700/100000], recon_Loss: 0.1176, G_Loss: 0.4936, net1_Loss: 0.1773, net2_Loss: 0.2018, \n",
            "Step [93800/100000], recon_Loss: 0.1260, G_Loss: 0.6530, net1_Loss: 0.1236, net2_Loss: 0.3823, \n",
            "Step [93900/100000], recon_Loss: 0.1289, G_Loss: 0.6560, net1_Loss: 0.0729, net2_Loss: 0.2323, \n",
            "Step [94000/100000], recon_Loss: 0.1305, G_Loss: 0.6750, net1_Loss: 0.0222, net2_Loss: 0.1133, \n",
            "Step [94100/100000], recon_Loss: 0.1256, G_Loss: 0.6752, net1_Loss: 0.0079, net2_Loss: 0.3953, \n",
            "Step [94200/100000], recon_Loss: 0.1275, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1728, \n",
            "Step [94300/100000], recon_Loss: 0.1308, G_Loss: 0.6766, net1_Loss: 0.1353, net2_Loss: 0.3103, \n",
            "Step [94400/100000], recon_Loss: 0.1211, G_Loss: 0.6798, net1_Loss: 0.0747, net2_Loss: 0.1008, \n",
            "Step [94500/100000], recon_Loss: 0.1311, G_Loss: 0.6522, net1_Loss: 0.3998, net2_Loss: 1.4336, \n",
            "Step [94600/100000], recon_Loss: 0.1251, G_Loss: 0.6548, net1_Loss: 0.0835, net2_Loss: 0.3135, \n",
            "Step [94700/100000], recon_Loss: 0.1263, G_Loss: 0.5908, net1_Loss: 0.0125, net2_Loss: 0.1032, \n",
            "Step [94800/100000], recon_Loss: 0.1253, G_Loss: 0.6530, net1_Loss: 0.0452, net2_Loss: 0.0822, \n",
            "Step [94900/100000], recon_Loss: 0.1298, G_Loss: 0.6511, net1_Loss: 0.0103, net2_Loss: 0.0629, \n",
            "Step [95000/100000], recon_Loss: 0.1252, G_Loss: 0.6725, net1_Loss: 0.0016, net2_Loss: 0.0559, \n",
            "Step [95100/100000], recon_Loss: 0.1185, G_Loss: 0.6038, net1_Loss: 0.0440, net2_Loss: 0.0596, \n",
            "Step [95200/100000], recon_Loss: 0.1319, G_Loss: 0.6533, net1_Loss: 0.0145, net2_Loss: 0.4630, \n",
            "Step [95300/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0009, net2_Loss: 0.1252, \n",
            "Step [95400/100000], recon_Loss: 0.1246, G_Loss: 0.6189, net1_Loss: 0.0349, net2_Loss: 0.1522, \n",
            "Step [95500/100000], recon_Loss: 0.1293, G_Loss: 0.6947, net1_Loss: 0.0000, net2_Loss: 0.3424, \n",
            "Step [95600/100000], recon_Loss: 0.1223, G_Loss: 0.6533, net1_Loss: 0.0114, net2_Loss: 0.1099, \n",
            "Step [95700/100000], recon_Loss: 0.1281, G_Loss: 0.5943, net1_Loss: 0.2077, net2_Loss: 0.4708, \n",
            "Step [95800/100000], recon_Loss: 0.1246, G_Loss: 0.6569, net1_Loss: 0.1347, net2_Loss: 0.1028, \n",
            "Step [95900/100000], recon_Loss: 0.1245, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1404, \n",
            "Step [96000/100000], recon_Loss: 0.1177, G_Loss: 0.4814, net1_Loss: 0.1618, net2_Loss: 0.1054, \n",
            "Step [96100/100000], recon_Loss: 0.1259, G_Loss: 0.6610, net1_Loss: 0.2809, net2_Loss: 0.7609, \n",
            "Step [96200/100000], recon_Loss: 0.1290, G_Loss: 0.6569, net1_Loss: 0.0315, net2_Loss: 0.1260, \n",
            "Step [96300/100000], recon_Loss: 0.1304, G_Loss: 0.6895, net1_Loss: 0.0171, net2_Loss: 0.0522, \n",
            "Step [96400/100000], recon_Loss: 0.1253, G_Loss: 0.6731, net1_Loss: 0.0020, net2_Loss: 0.4837, \n",
            "Step [96500/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.1805, \n",
            "Step [96600/100000], recon_Loss: 0.1307, G_Loss: 0.6724, net1_Loss: 0.0375, net2_Loss: 0.1974, \n",
            "Step [96700/100000], recon_Loss: 0.1211, G_Loss: 0.6729, net1_Loss: 0.0241, net2_Loss: 0.1172, \n",
            "Step [96800/100000], recon_Loss: 0.1310, G_Loss: 0.6519, net1_Loss: 0.0214, net2_Loss: 0.3899, \n",
            "Step [96900/100000], recon_Loss: 0.1251, G_Loss: 0.6350, net1_Loss: 0.0985, net2_Loss: 0.1540, \n",
            "Step [97000/100000], recon_Loss: 0.1264, G_Loss: 0.5979, net1_Loss: 0.0310, net2_Loss: 0.4985, \n",
            "Step [97100/100000], recon_Loss: 0.1254, G_Loss: 0.6546, net1_Loss: 0.0539, net2_Loss: 0.1994, \n",
            "Step [97200/100000], recon_Loss: 0.1298, G_Loss: 0.6541, net1_Loss: 0.0128, net2_Loss: 0.1055, \n",
            "Step [97300/100000], recon_Loss: 0.1252, G_Loss: 0.6747, net1_Loss: 0.0703, net2_Loss: 0.1032, \n",
            "Step [97400/100000], recon_Loss: 0.1185, G_Loss: 0.6011, net1_Loss: 0.3141, net2_Loss: 0.0947, \n",
            "Step [97500/100000], recon_Loss: 0.1319, G_Loss: 0.6615, net1_Loss: 0.0015, net2_Loss: 0.2336, \n",
            "Step [97600/100000], recon_Loss: 0.1248, G_Loss: 0.6931, net1_Loss: 0.0201, net2_Loss: 0.0841, \n",
            "Step [97700/100000], recon_Loss: 0.1247, G_Loss: 0.6257, net1_Loss: 0.0565, net2_Loss: 0.0943, \n",
            "Step [97800/100000], recon_Loss: 0.1293, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0933, \n",
            "Step [97900/100000], recon_Loss: 0.1222, G_Loss: 0.6642, net1_Loss: 0.0138, net2_Loss: 0.0630, \n",
            "Step [98000/100000], recon_Loss: 0.1282, G_Loss: 0.5945, net1_Loss: 0.0377, net2_Loss: 0.3161, \n",
            "Step [98100/100000], recon_Loss: 0.1245, G_Loss: 0.6529, net1_Loss: 0.0674, net2_Loss: 0.1440, \n",
            "Step [98200/100000], recon_Loss: 0.1246, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.2925, \n",
            "Step [98300/100000], recon_Loss: 0.1177, G_Loss: 0.5008, net1_Loss: 0.0755, net2_Loss: 0.0514, \n",
            "Step [98400/100000], recon_Loss: 0.1259, G_Loss: 0.6520, net1_Loss: 0.0299, net2_Loss: 0.1917, \n",
            "Step [98500/100000], recon_Loss: 0.1289, G_Loss: 0.6537, net1_Loss: 0.0813, net2_Loss: 0.8374, \n",
            "Step [98600/100000], recon_Loss: 0.1304, G_Loss: 0.6751, net1_Loss: 0.0086, net2_Loss: 0.4664, \n",
            "Step [98700/100000], recon_Loss: 0.1253, G_Loss: 0.6757, net1_Loss: 0.0028, net2_Loss: 0.5004, \n",
            "Step [98800/100000], recon_Loss: 0.1274, G_Loss: 0.6931, net1_Loss: 0.0000, net2_Loss: 0.0309, \n",
            "Step [98900/100000], recon_Loss: 0.1308, G_Loss: 0.6721, net1_Loss: 0.0764, net2_Loss: 0.1409, \n",
            "Step [99000/100000], recon_Loss: 0.1211, G_Loss: 0.6717, net1_Loss: 0.0527, net2_Loss: 0.0713, \n",
            "Step [99100/100000], recon_Loss: 0.1311, G_Loss: 0.6512, net1_Loss: 0.0179, net2_Loss: 0.9891, \n",
            "Step [99200/100000], recon_Loss: 0.1253, G_Loss: 0.6509, net1_Loss: 0.2320, net2_Loss: 1.1331, \n",
            "Step [99300/100000], recon_Loss: 0.1263, G_Loss: 0.5920, net1_Loss: 0.1906, net2_Loss: 0.1360, \n",
            "Step [99400/100000], recon_Loss: 0.1253, G_Loss: 0.6517, net1_Loss: 0.0835, net2_Loss: 0.3797, \n",
            "Step [99500/100000], recon_Loss: 0.1297, G_Loss: 0.6528, net1_Loss: 0.0344, net2_Loss: 0.1101, \n",
            "Step [99600/100000], recon_Loss: 0.1252, G_Loss: 0.6720, net1_Loss: 0.0089, net2_Loss: 0.0506, \n",
            "Step [99700/100000], recon_Loss: 0.1185, G_Loss: 0.6030, net1_Loss: 0.0342, net2_Loss: 0.0565, \n",
            "Step [99800/100000], recon_Loss: 0.1318, G_Loss: 0.6555, net1_Loss: 0.0040, net2_Loss: 0.0750, \n",
            "Step [99900/100000], recon_Loss: 0.1247, G_Loss: 0.6931, net1_Loss: 0.0001, net2_Loss: 0.0526, \n",
            "Step [100000/100000], recon_Loss: 0.1245, G_Loss: 0.6232, net1_Loss: 0.0038, net2_Loss: 0.0953, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt37XNJLn03b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the Encoder\n",
        "torch.save(Q.state_dict(),'Q_CF_IHDP_mask.pt')\n",
        "torch.save(net_1.state_dict(),'Y1_ihdp_mask.pt')\n",
        "torch.save(net_0.state_dict(),'Y0_ihdp_mask.pt')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KysFO_KAlm7y",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv1oR56flo05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b3f984e-7784-4399-d376-00f0ddf5f146"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import preprocessing\n",
        "from mpl_toolkits import mplot3d"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyN9nBvalzGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_ihdp_data():\n",
        "    csv_loader = []\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/ihdp/csv/ihdp_npci_7.csv\", header=None)\n",
        "    x= df.iloc[:, 5:].values\n",
        "    min_max = preprocessing.MinMaxScaler()\n",
        "    X = min_max.fit_transform(x)\n",
        "    trt = df.iloc[:,0].to_numpy()\n",
        "    y = df.iloc[:,1].to_numpy()\n",
        "    ycf = df.iloc[:,2].to_numpy()\n",
        "    return X,trt,y, ycf\n",
        "    \n",
        "\n",
        "def load_LEIE_data():\n",
        "    df = pd.read_csv('LEIE_noNPI.csv', header= None)\n",
        "    #create a balanced test set\n",
        "    test = df.loc[ df[17] == 1 ]\n",
        "    test = test.append( df.loc[ df[17] == 0 ].sample(n=5000, replace=False))   \n",
        "    x= test.values\n",
        "    min_max = preprocessing.MinMaxScaler()\n",
        "    x_scaled = min_max.fit_transform(x)\n",
        "    test = pd.DataFrame(x_scaled)\n",
        "    images = test.iloc[:,:17].to_numpy()\n",
        "    labels = test.iloc[:,17].to_numpy()\n",
        "    return images, labels\n",
        "\n",
        "def load_agg_data():\n",
        "    df = pd.read_csv('agg_noNPI.csv', header= None)\n",
        "    #create a balanced test set\n",
        "    test = df.loc[ df[25] == True ]\n",
        "    test = test.append( df.loc[ df[25] == False ].sample(n=5000, replace=False))   \n",
        "    images = test.iloc[:,:25].to_numpy()\n",
        "    labels = test.iloc[:,25].to_numpy()\n",
        "    return images, labels\n",
        "\n",
        "def load_NAgg_data():\n",
        "    df = pd.read_csv('NA_FL_noNPI.csv', header= None)\n",
        "    #create a balanced test set\n",
        "    test = df.loc[ df[10] == 1 ]\n",
        "    test = test.append( df.loc[ df[10] == 0 ].sample(n=5000, replace=False))\n",
        "    x= test.values\n",
        "    min_max = preprocessing.MinMaxScaler()\n",
        "    x_scaled = min_max.fit_transform(x)\n",
        "    test = pd.DataFrame(x_scaled)   \n",
        "    images = test.iloc[:,:10].to_numpy()\n",
        "    labels = test.iloc[:,10].to_numpy()\n",
        "    return images, labels\n",
        "\n",
        "def load_set_data():\n",
        "    df = pd.read_csv('set_1.csv')\n",
        "    images = df.iloc[:,4:24].to_numpy()\n",
        "    labels = df.iloc[:,3].to_numpy()\n",
        "    y = df.iloc[:,24].to_numpy()\n",
        "    return images, labels, y\n",
        "\n",
        "def load_trans_data():\n",
        "    df = pd.read_csv('ee_embed_mean_cat.csv', header=None)\n",
        "    del df[300]\n",
        "    x= df.values\n",
        "    min_max = preprocessing.MinMaxScaler()\n",
        "    x_scaled = min_max.fit_transform(x)\n",
        "    df = pd.DataFrame(x_scaled)\n",
        "    images = df.iloc[:,:300].to_numpy()\n",
        "    labels = df.iloc[:,300].to_numpy()\n",
        "    return images, labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9ZW7hel4jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_manifold():\n",
        "\n",
        "    #Encoder\n",
        "    class Q_net(nn.Module):  \n",
        "        def __init__(self,X_dim,N,z_dim):\n",
        "            super(Q_net, self).__init__()\n",
        "            self.lin1 = nn.Linear(X_dim, N)\n",
        "            self.lin2 = nn.Linear(N, N)\n",
        "            self.lin3gauss = nn.Linear(N, z_dim)\n",
        "        def forward(self, x):\n",
        "            x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
        "            x = F.relu(x)\n",
        "            xgauss = self.lin3gauss(x)\n",
        "            return xgauss                                        \n",
        "\n",
        "    X, trt, y =  load_ihdp_data() \n",
        "    #load_NAgg_data() \n",
        "    #load_LEIE_data() \n",
        "    # #load_agg_data()\n",
        "\n",
        "    # Convert to Tensors\n",
        "    X = torch.from_numpy(X).float()\n",
        "    trt = torch.from_numpy(trt).float()\n",
        "    y = torch.from_numpy(y).float()\n",
        "\n",
        "    X, trt, y = to_var(X.view(X.size(0), -1)), to_var(trt), to_var(y)\n",
        "\n",
        "    # load the weights again\n",
        "    z_red_dims = 12\n",
        "    Q = Q_net(25,1000,z_red_dims).cuda()\n",
        "    Q.load_state_dict(torch.load('Q_CF_IHDP_mask.pt'))\n",
        "    Q.eval() #turrn off dropout\n",
        "\n",
        "    # Run through encoder\n",
        "    z_out = Q(X)\n",
        "\n",
        "    # plot the manifold\n",
        "    df_tsne = pd.DataFrame(z_out.data.cpu().numpy())\n",
        "\n",
        "    Z_embed = TSNE(n_components=2, n_iter=1000, perplexity=50).fit_transform(df_tsne)\n",
        "    df_tsne['trt'] = trt.data.cpu().numpy()\n",
        "\n",
        "    df_tsne['tsne-2d-one'] = Z_embed[:,0]\n",
        "    df_tsne['tsne-2d-two'] = Z_embed[:,1]\n",
        "    \n",
        "    plt.figure(figsize=(16,10))\n",
        "    g = sns.scatterplot(\n",
        "        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "        hue=\"trt\",\n",
        "        # palette = sns.color_palette(\"Paired\",3),\n",
        "        #palette = sns.hls_palette(3, l=.3, s=.8),\n",
        "        # palette=['pale red','medium green','denim blue'],\n",
        "        palette=sns.color_palette(\"husl\", 3),\n",
        "        data=df_tsne,\n",
        "        legend=\"full\"#,\n",
        "        #alpha=0.3\n",
        "    )\n",
        "    g.figure.savefig(\"z_ihdp_1.png\")\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = plt.axes(projection='3d')\n",
        "    xdata = Z_embed[:,0]\n",
        "    ydata = Z_embed[:,1]\n",
        "    zdata = Z_embed[:,2]\n",
        "\n",
        "    ax.scatter3D(xdata, ydata, zdata, c=labels.data.cpu().numpy());\n",
        "    fig.savefig('z_trans_sti_3d.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mL9VKEWl8LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_acc():\n",
        "    #Encoder\n",
        "    class Q_net(nn.Module):  \n",
        "        def __init__(self,X_dim,N,z_dim):\n",
        "            super(Q_net, self).__init__()\n",
        "            self.lin1 = nn.Linear(X_dim, N)\n",
        "            self.lin2 = nn.Linear(N, N)\n",
        "            self.lin3gauss = nn.Linear(N, z_dim)\n",
        "        def forward(self, x):\n",
        "            x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
        "            x = F.relu(x)\n",
        "            xgauss = self.lin3gauss(x)\n",
        "            return xgauss  \n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self, input_size=2, hidden_size=500):\n",
        "            super(Net, self).__init__()\n",
        "            self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "            self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "            self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
        "            self.fc4 = nn.Linear(hidden_size, 1)  \n",
        "        def forward(self, x):\n",
        "            out = self.fc1(x)\n",
        "            out = F.relu(out)\n",
        "            out = self.fc2(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.fc3(out)\n",
        "            out = F.relu(out)\n",
        "            return self.fc4(out)                                  \n",
        "\n",
        "    X, trt, y, ycf = load_ihdp_data()\n",
        "\n",
        "    # Convert to Tensors\n",
        "    X = torch.from_numpy(X).float()\n",
        "    trt = torch.from_numpy(trt).float()\n",
        "    y = torch.from_numpy(y).float()\n",
        "    ycf = torch.from_numpy(ycf).float()\n",
        "    X, trt, y, ycf = to_var(X.view(X.size(0), -1)), to_var(trt), to_var(y), to_var(ycf)\n",
        "\n",
        "    # load the weights again\n",
        "    z_red_dims = 16\n",
        "    Q = Q_net(25,1000,z_red_dims).cuda()\n",
        "    Q.load_state_dict(torch.load('Q_CF_IHDP_mask.pt'))\n",
        "    Q.eval() #turn off dropout\n",
        "\n",
        "    net_1 = Net(input_size = z_red_dims, hidden_size=500).cuda()\n",
        "    net_1.load_state_dict(torch.load('Y1_ihdp_mask.pt'))\n",
        "    net_1.eval()\n",
        "    net_0 = Net(input_size = z_red_dims, hidden_size=500).cuda()\n",
        "    net_0.load_state_dict(torch.load('Y0_ihdp_mask.pt'))\n",
        "    net_0.eval()\n",
        "\n",
        "    z_out = Q(X)\n",
        "    y1_hat = net_1(z_out)\n",
        "    y0_hat = net_0(z_out)\n",
        "\n",
        "    y11 = y[trt==1].data.cpu().numpy()\n",
        "    y10 = ycf[trt==0].data.cpu().numpy()\n",
        "    y00 = y[trt==0].data.cpu().numpy()\n",
        "    y01 = ycf[trt==1].data.cpu().numpy()\n",
        "    \n",
        "    y1 = np.append(y11,y10)\n",
        "    y0 = np.append(y01,y00)\n",
        "    \n",
        "    ATE = np.mean( np.mean(y1) - np.mean(y0)   )\n",
        "    ATE_hat = y1_hat.data.cpu().numpy() - y0_hat.data.cpu().numpy()\n",
        "    delta = abs( ATE - np.mean(ATE_hat))\n",
        "\n",
        "    TE = np.mean(y1- y0)\n",
        "    PEHE = np.sqrt(np.mean( (TE - ATE_hat)**2))\n",
        "\n",
        "    ITE = np.mean(abs(TE - ATE_hat))\n",
        "\n",
        "    # plot the manifold\n",
        "    print(\"Eps_ITE Eps_ATE, PEHE,  :\"ITE, delta, PEHE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kK9BAwPl_Bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57fae007-04dc-400d-fa42-93bae02e87dd"
      },
      "source": [
        "calc_acc()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ATE, PEHE, ITE : 0.28444242 1.739429 1.3612411\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}